"""
Procesador de batches inteligente para agrupar contenido de m칰ltiples p치ginas
hasta un l칤mite de caracteres antes de enviar al LLM
"""

from typing import List, Dict, Any, Tuple
import logging

logger = logging.getLogger(__name__)


def create_batches(
    page_contents: List[Dict[str, Any]], 
    batch_size: int = 500000
) -> List[Tuple[List[Dict[str, Any]], str]]:
    """
    Agrupa contenido de m칰ltiples p치ginas en batches hasta el l칤mite de caracteres
    
    Args:
        page_contents: Lista de diccionarios con contenido de p치ginas. Cada dict debe tener:
            - "markdown_cleaned": markdown limpio de la p치gina
            - "url": URL de origen
            - Cualquier otro metadata necesario
        batch_size: Tama침o m치ximo por batch en caracteres (default: 500,000)
        
    Returns:
        Lista de tuplas (pages_in_batch, combined_markdown) donde:
            - pages_in_batch: Lista de dicts de p치ginas incluidas en este batch
            - combined_markdown: Markdown combinado de todas las p치ginas del batch
    """
    if not page_contents:
        return []
    
    batches = []
    current_batch_pages = []
    current_batch_size = 0
    separator = "\n\n---\n\n"  # Separador entre p치ginas
    
    for page_data in page_contents:
        markdown = page_data.get("markdown_cleaned", "")
        if not markdown:
            logger.warning(f"P치gina {page_data.get('url', 'unknown')} no tiene markdown_cleaned, omitiendo")
            continue
        
        markdown_size = len(markdown)
        separator_size = len(separator) if current_batch_pages else 0
        
        # Si agregar esta p치gina excede el l칤mite, crear un nuevo batch
        if current_batch_pages and (current_batch_size + separator_size + markdown_size > batch_size):
            # Crear batch con las p치ginas acumuladas
            combined_markdown = separator.join([
                page.get("markdown_cleaned", "") 
                for page in current_batch_pages
            ])
            batches.append((current_batch_pages.copy(), combined_markdown))
            
            # Iniciar nuevo batch con esta p치gina
            current_batch_pages = [page_data]
            current_batch_size = markdown_size
        else:
            # Agregar p치gina al batch actual
            current_batch_pages.append(page_data)
            current_batch_size += separator_size + markdown_size
    
    # Agregar 칰ltimo batch si tiene contenido
    if current_batch_pages:
        combined_markdown = separator.join([
            page.get("markdown_cleaned", "") 
            for page in current_batch_pages
        ])
        batches.append((current_batch_pages, combined_markdown))
    
    logger.info(f"游닍 Creados {len(batches)} batches desde {len(page_contents)} p치ginas")
    for i, (pages, markdown) in enumerate(batches):
        logger.info(f"  Batch {i+1}: {len(pages)} p치ginas, {len(markdown):,} caracteres")
    
    return batches


def extract_urls_from_batch(pages_in_batch: List[Dict[str, Any]]) -> str:
    """
    Extrae las URLs de las p치ginas en un batch para usar como contexto
    
    Args:
        pages_in_batch: Lista de diccionarios de p치ginas
        
    Returns:
        String con las URLs separadas por comas o la URL principal
    """
    urls = [page.get("url", "") for page in pages_in_batch if page.get("url")]
    if len(urls) == 1:
        return urls[0]
    elif len(urls) > 1:
        return f"{urls[0]} (+{len(urls)-1} p치ginas m치s)"
    return ""

