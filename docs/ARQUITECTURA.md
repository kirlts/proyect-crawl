# Arquitectura del Sistema - Gu√≠a Maestra (v4.4)

> Este documento es la **fuente de verdad** sobre c√≥mo funciona internamente el sistema:
> scraping, extracci√≥n con LLM, predicciones, manejo de historial, depuraci√≥n, UI y
> rotaci√≥n de API keys. Se mantiene alineado con el estado actual del c√≥digo.

## üìã Tabla de Contenidos

1. [Visi√≥n General](#visi√≥n-general)
2. [Estructura Modular](#estructura-modular)
3. [Modelos de Datos](#modelos-de-datos)
4. [Flujos de Procesamiento](#flujos-de-procesamiento)
5. [Extracci√≥n Determin√≠stica vs LLM](#extracci√≥n-determin√≠stica-vs-llm)
6. [Manejo de Errores y Reintentos](#manejo-de-errores-y-reintentos)
7. [Manejo de M√∫ltiples Versiones de Predicciones](#manejo-de-m√∫ltiples-versiones-de-predicciones)
8. [Decisiones de Dise√±o](#decisiones-de-dise√±o)
9. [Gu√≠a para Desarrollo](#gu√≠a-para-desarrollo)
10. [Extensibilidad](#extensibilidad)
11. [Convenciones de C√≥digo](#convenciones-de-c√≥digo)
12. [Recursos y Referencias](#recursos-y-referencias)

---

## Visi√≥n General

Sistema para **extraer, limpiar, historizar y predecir** informaci√≥n de concursos de financiamiento (principalmente ANID y otros sitios p√∫blicos).

### Objetivos Principales

- **Modular**: Servicios separados para scraping/extracci√≥n y predicci√≥n
- **Escalable**: F√°cil agregar nuevos sitios, modelos LLM o flujos
- **Mantenible**: C√≥digo estructurado con separaci√≥n clara UI/negocio
- **Auditable**: Archivos de debug detallados para cada proceso
- **Robusto**: Manejo expl√≠cito de rate limits, timeouts, errores HTTP y reintentos autom√°ticos
- **Reutilizable**: Datos cr√≠ticos (como `previous_concursos`) se guardan en historial y se reutilizan

### Stack Tecnol√≥gico

- **Python 3.10+**: Lenguaje principal
- **Streamlit**: Framework para UI web
- **Crawl4AI**: Framework de web scraping con Playwright
- **Google Gemini API** (`gemini-2.5-flash-lite` por defecto): LLM para extracci√≥n y predicci√≥n
- **Pydantic**: Modelos fuertemente tipados y validaci√≥n
- **Asyncio**: Scraping as√≠ncrono de p√°ginas individuales
- **Requests**: Llamadas REST directas a Gemini con Structured Outputs
- **BeautifulSoup**: Parsing fino de ANID para "Concursos anteriores"

---

## Estructura Modular

```
proyect-crawl/
‚îú‚îÄ‚îÄ models/                    # Modelos de datos centralizados
‚îÇ   ‚îú‚îÄ‚îÄ concurso.py            # Modelo Pydantic Concurso
‚îÇ   ‚îî‚îÄ‚îÄ prediccion.py         # Modelos de predicci√≥n
‚îÇ
‚îú‚îÄ‚îÄ services/                  # Servicios de negocio (orquestaci√≥n)
‚îÇ   ‚îú‚îÄ‚îÄ extraction_service.py  # Scraping + extracci√≥n LLM + historial
‚îÇ   ‚îî‚îÄ‚îÄ prediction_service.py  # Generaci√≥n de predicciones
‚îÇ
‚îú‚îÄ‚îÄ crawler/                   # M√≥dulo de scraping web
‚îÇ   ‚îú‚îÄ‚îÄ scraper.py             # WebScraper principal (usa estrategias)
‚îÇ   ‚îú‚îÄ‚îÄ strategies/            # NUEVO: Estrategias por sitio
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py        # Registro de estrategias
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_strategy.py   # Clase base abstracta
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ anid_strategy.py   # Estrategia espec√≠fica ANID
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ generic_strategy.py # Estrategia gen√©rica (fallback)
‚îÇ   ‚îú‚îÄ‚îÄ pagination/            # NUEVO: M√≥dulo de paginaci√≥n
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_pagination.py # Clase base
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ anid_pagination.py # Paginaci√≥n din√°mica ANID
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ generic_pagination.py # Paginaci√≥n tradicional
‚îÇ   ‚îú‚îÄ‚îÄ markdown_processor.py  # Limpieza y optimizaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ batch_processor.py     # Agrupaci√≥n en batches
‚îÇ   ‚îî‚îÄ‚îÄ pagination.py          # Detecci√≥n de paginaci√≥n (legacy, mantenido para compatibilidad)
‚îÇ
‚îú‚îÄ‚îÄ llm/                       # Integraci√≥n con LLM
‚îÇ   ‚îú‚îÄ‚îÄ gemini_client.py       # Gesti√≥n de API keys y rotaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ prompts.py             # Templates de prompts
‚îÇ   ‚îú‚îÄ‚îÄ predictor.py           # L√≥gica de predicci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ extractors/
‚îÇ       ‚îî‚îÄ‚îÄ llm_extractor.py   # Extracci√≥n con LLM (REST API)
‚îÇ
‚îú‚îÄ‚îÄ utils/                     # Utilidades generales
‚îÇ   ‚îú‚îÄ‚îÄ extractors/            # NUEVO: Extractores espec√≠ficos por sitio
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_extractor.py  # Clase base
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ anid_extractor.py  # Extracci√≥n "Concursos anteriores" ANID
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ generic_extractor.py # Extracci√≥n gen√©rica
‚îÇ   ‚îú‚îÄ‚îÄ api_key_manager.py     # Gesti√≥n y rotaci√≥n de API keys
‚îÇ   ‚îú‚îÄ‚îÄ file_manager.py        # Guardado, carga y debug
‚îÇ   ‚îú‚îÄ‚îÄ history_manager.py     # Gesti√≥n de historial
‚îÇ   ‚îú‚îÄ‚îÄ date_parser.py         # Parsing de fechas
‚îÇ   ‚îú‚îÄ‚îÄ deterministic_date_extractor.py # Extracci√≥n determin√≠stica (nombre, fechas)
‚îÇ   ‚îî‚îÄ‚îÄ anid_previous_concursos.py # Extracci√≥n "Concursos anteriores" (legacy, mantenido para compatibilidad)
‚îÇ
‚îú‚îÄ‚îÄ data/                      # Datos (se crea autom√°ticamente)
‚îÇ   ‚îú‚îÄ‚îÄ history/               # Historial por sitio
‚îÇ   ‚îú‚îÄ‚îÄ predictions/           # Predicciones y no-predecibles
‚îÇ   ‚îú‚îÄ‚îÄ raw_pages/             # Cache persistente de HTML/Markdown por sitio/URL (sin compresi√≥n)
‚îÇ   ‚îî‚îÄ‚îÄ debug/                 # Archivos de debug
‚îÇ       ‚îú‚îÄ‚îÄ scraping/          # Debug de scraping
‚îÇ       ‚îú‚îÄ‚îÄ predictions/       # Debug de predicciones
‚îÇ       ‚îî‚îÄ‚îÄ repair/            # Debug de reparaci√≥n
‚îÇ
‚îú‚îÄ‚îÄ config/                    # NUEVO: M√≥dulo de configuraci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py            # Exporta configuraciones
‚îÇ   ‚îú‚îÄ‚îÄ global_config.py       # Configuraci√≥n global
‚îÇ   ‚îî‚îÄ‚îÄ sites.py               # Configuraci√≥n por sitio
‚îú‚îÄ‚îÄ main.py                    # UI Streamlit
‚îú‚îÄ‚îÄ config.py                  # Configuraci√≥n centralizada (wrapper para compatibilidad)
‚îî‚îÄ‚îÄ docs/                      # Documentaci√≥n
```

### Descripci√≥n de M√≥dulos Clave

#### `crawler/scraper.py`

**Responsabilidad**: Scraping web con Crawl4AI usando estrategias por sitio.

- `scrape_url_with_pagination()`: Scraping con paginaci√≥n usando estrategias (reemplaza `scrape_url_with_dynamic_pagination()`)
- Obtiene la estrategia apropiada seg√∫n la URL usando `get_strategy_for_url()`
- Delega la l√≥gica de paginaci√≥n a la estrategia espec√≠fica del sitio
- `scrape_url_simple()`: Scraping simple para sitios sin paginaci√≥n
- `scrape_url()`: Scraping b√°sico de una URL

#### `crawler/strategies/`

**Responsabilidad**: Sistema de estrategias para manejar diferentes sitios (l√≥gica espec√≠fica aislada del c√≥digo gen√©rico).

- **`base_strategy.py`**: Clase abstracta `ScrapingStrategy` que define la interfaz:
  - `site_name`, `site_display_name`: Propiedades del sitio
  - `get_crawler_config()`: Configuraci√≥n espec√≠fica de Crawl4AI
  - `supports_dynamic_pagination()`: Indica si requiere paginaci√≥n din√°mica
  - `scrape_with_pagination()`: M√©todo principal de scraping con paginaci√≥n (o bypass si el sitio es de una sola p√°gina)
  - `extract_previous_concursos()`: Extracci√≥n de "concursos anteriores" (opcional)
  - `get_organismo_name()`: Nombre del organismo
  - `get_known_subdirecciones()`: Subdirecciones conocidas (opcional)

- **`anid_strategy.py`** (ANID):
  - Usa `AnidPagination` para paginaci√≥n din√°mica JetEngine.
  - Usa `AnidExtractor` para extraer "Concursos anteriores".
  - Configuraci√≥n espec√≠fica: `wait_for: "css:.jet-listing-grid__item"`, waits y JS para contenido AJAX.
  - Organismo: "ANID". Subdirecciones conocidas: Capital Humano, Investigaci√≥n Aplicada, etc.

- **`centro_estudios_strategy.py`** (Centro Estudios MINEDUC / FONIDE):
  - Sitio est√°tico de una sola p√°gina; sin paginaci√≥n y sin LLM.
  - Bypass de waits pesados/JS: timeout corto (‚âà15s), JS trivial, sin esperas JetEngine.
  - Extracci√≥n determinista del bloque ‚ÄúConvocatoria actual (FONIDE NN)‚Äù: nombre adaptable (FONIDE 16/17/‚Ä¶), fecha de consultas (apertura) y fecha de postulaciones (cierre).
  - Guarda HTML/Markdown completos en cache e historial; no hay `previous_concursos` externos.

- **`generic_strategy.py`**:
  - Fallback para sitios est√°ndar sin l√≥gica espec√≠fica.
  - Usa paginaci√≥n tradicional (enlaces HTML).
  - Configuraci√≥n b√°sica de Crawl4AI; no extrae "concursos anteriores".

- **`__init__.py`**: Registro de estrategias:
  - `STRATEGY_REGISTRY`: Diccionario que mapea dominios a clases de estrategia
  - `register_strategy()`: Registra una estrategia para un dominio
  - `get_strategy_for_url()`: Obtiene estrategia seg√∫n URL (retorna GenericStrategy si no hay espec√≠fica)
  - `get_strategy_for_site()`: Obtiene estrategia seg√∫n nombre de sitio

#### `crawler/pagination/`

**Responsabilidad**: M√≥dulo de paginaci√≥n para diferentes tipos de sitios.

- **`base_pagination.py`**: Clase abstracta `BasePagination` con m√©todo `scrape_pages()`
- **`anid_pagination.py`**: Implementaci√≥n de paginaci√≥n din√°mica para ANID:
  - Maneja clicks en botones JavaScript de JetEngine
  - Espera inteligente de contenido AJAX
  - Detecci√≥n robusta de √∫ltima p√°gina (verifica bot√≥n ">")
  - Hooks espec√≠ficos de Playwright para esperar carga de contenido
- **`generic_pagination.py`**: Paginaci√≥n tradicional usando enlaces HTML:
  - Busca enlaces de paginaci√≥n en el HTML
  - Scrapea cada p√°gina individualmente

#### `utils/extractors/`

**Responsabilidad**: Extractores de datos espec√≠ficos por sitio.

- **`base_extractor.py`**: Clase abstracta `BaseExtractor` con m√©todo `extract_previous_concursos()`
- **`anid_extractor.py`**: Extractor espec√≠fico para ANID:
  - Extrae "Concursos anteriores" usando selectores JetEngine
  - L√≥gica mejorada de extracci√≥n de nombres y a√±os
  - Filtra subdirecciones conocidas
- **`generic_extractor.py`**: Extractor gen√©rico que retorna lista vac√≠a

#### `config/sites.py`

**Responsabilidad**: Configuraci√≥n espec√≠fica por sitio.

- `SITE_CONFIGS`: Diccionario con configuraci√≥n por dominio
- `get_site_config()`: Obtiene configuraci√≥n para un dominio
- `get_site_name_for_history()`: Convierte nombre de sitio a nombre para historial
- `SEED_URLS`: URLs semilla por sitio
- `SITE_NAME_MAPPING`: Mapeo de nombres de sitio a nombres para historial

#### `services/extraction_service.py`

**Responsabilidad**: Orquestar scraping, extracci√≥n con LLM y actualizaci√≥n de historial.

- **Usa estrategias**: Obtiene estrategia apropiada con `get_strategy_for_url()`
- **Sin l√≥gica hardcodeada**: Todas las decisiones espec√≠ficas de sitio se delegan a estrategias
- Scraping de URLs de listado (con o sin paginaci√≥n, seg√∫n estrategia)
- Extracci√≥n con LLM desde markdown combinado
- Scraping de p√°ginas individuales de concursos
- Enriquecimiento por segunda pasada con LLM
- Extracci√≥n de "concursos anteriores" usando `strategy.extract_previous_concursos()`
- Detecci√≥n y recuperaci√≥n autom√°tica de p√©rdida de datos
- Actualizaci√≥n del historial (incluyendo `previous_concursos`)
- Reparaci√≥n de concursos incompletos
- Generaci√≥n de debug de scraping

#### `services/prediction_service.py`

**Responsabilidad**: Generar predicciones usando datos del historial (sin scraping adicional).

- Trabaja **solo** con datos ya presentes en el historial
- Usa `previous_concursos` para alimentar el LLM
- **Batching optimizado**: 
  - Filtra casos de `self_reference` ANTES de crear batches
  - Agrupa concursos predecibles en batches de exactamente 10
  - Garantiza que cada batch tenga 10 concursos (excepto el √∫ltimo si hay menos)
- Predicciones en lote (con filtros) e individuales (desde UI)
- Maneja concursos no predecibles (`self_reference`, `llm_rejected`)
- Persiste predicciones y no-predecibles en archivos JSON
- Emite debug de predicciones (masivas e individuales)

#### `llm/predictor.py`

**Responsabilidad**: Construir prompts y llamar al LLM para predicciones.

- **M√©todos de predicci√≥n**:
  - `predict_from_previous_concursos()`: Predicci√≥n individual (2000 tokens)
  - `predict_from_previous_concursos_batch()`: Predicci√≥n en batch (12000 tokens)
- Usa Structured Outputs con `PrediccionConcurso` y `PrediccionBatchResponse`
- **Reintentos autom√°ticos**: Hasta 3 intentos para errores de parsing JSON
- **L√≠mites de tokens din√°micos**:
  - Predicciones individuales: 2000 tokens
  - Predicciones en batch: 12000 tokens (para acomodar 10 concursos con justificaciones)
- Manejo detallado de errores (HTTP, JSON, Pydantic, red)
- Prompts optimizados con lenguaje afirmativo y ejemplos conceptuales

#### `llm/extractors/llm_extractor.py`

**Responsabilidad**: Extraer informaci√≥n estructurada usando LLM.

- `extract_from_batch()`: Extrae concursos desde markdown combinado
- Construye prompts con Structured Outputs
- Ajusta `maxOutputTokens` din√°micamente seg√∫n tama√±o del batch
- **Reintento autom√°tico con aumento de tokens**: Si el JSON est√° truncado, aumenta `maxOutputTokens` y reintenta autom√°ticamente (hasta 3 veces, hasta 32000 tokens)
- Maneja rate limits, timeouts y errores de conexi√≥n
- Rotaci√≥n autom√°tica de API keys
- Validaci√≥n de p√©rdida de datos y re-extracci√≥n con modelo m√°s potente

#### `utils/history_manager.py`

**Responsabilidad**: Gestionar historial de concursos.

- `load_history()`, `save_history()`: Persistencia por sitio
- `update_history()`: Actualiza o crea entradas, maneja versiones
- Guarda `latest_page_content` y `previous_concursos` por URL
- `find_incomplete_concurso_urls()`: Identifica concursos con datos faltantes
- `fix_suspended_concursos_by_url()`: Corrige concursos suspendidos por URL
- `delete_concurso()`, `clear_history()`: Gesti√≥n de eliminaci√≥n

#### `utils/deterministic_date_extractor.py`

**Responsabilidad**: Extracci√≥n determin√≠stica de datos antes de usar LLM (optimizaci√≥n).

- `extract_nombre_deterministically()`: Extrae nombre desde `<title>`, `og:title`, `<h1>`, headings
- `extract_dates_deterministically()`: Extrae fechas desde patrones "Inicio:", "Cierre:"
- `extract_concurso_data_deterministically()`: Funci√≥n principal que combina ambas extracciones
- **Objetivo**: Reducir llamadas al LLM cuando los datos est√°n en formato est√°ndar

#### `utils/anid_previous_concursos.py`

**Responsabilidad**: Extraer informaci√≥n de "Concursos anteriores" de p√°ginas ANID.

- `extract_previous_concursos_from_html()`: Extrae nombres, fechas, URLs y a√±os de concursos anteriores
- **Extracci√≥n mejorada de nombres**: 
  - Prioriza texto del link, luego atributos `title` y `data-*`, luego slug de URL
  - Filtra textos gen√©ricos como "Ver m√°s", "Leer m√°s"
  - Filtra subdirecciones conocidas para evitar identificarlas como nombres de concursos
- **Extracci√≥n mejorada de a√±os**: Extrae desde m√∫ltiples fuentes (nombre, fecha_apertura, fecha_cierre, URL)
- Deduplicaci√≥n por nombre + fechas para evitar duplicados

#### `utils/file_manager.py`

**Responsabilidad**: Guardado, carga y debug de resultados.

- `save_debug_info_scraping()`: Debug de scraping
- `save_debug_info_predictions()`: Debug de predicciones en lote
- `save_debug_info_individual_prediction()`: Debug de predicciones individuales
- `save_debug_info_repair()`: Debug de reparaci√≥n
- `save_predictions()`/`load_predictions()`: Predicciones (evita duplicados)
- `save_unpredictable_concursos()`/`load_unpredictable_concursos()`: No-predecibles
- `delete_prediction()`, `clear_predictions()`: Gesti√≥n de eliminaci√≥n
- **Cache de p√°ginas individuales (sin compresi√≥n)**:
  - `save_page_cache(site, url, html, markdown)`: Guarda HTML/MD completos y actualiza √≠ndice por URL (sobrescribe si ya exist√≠a)
  - `load_page_cache(site, url)`: Recupera HTML/MD desde cache para reparaciones/predicciones antes de re-scrapear
  - √çndice por sitio en `data/raw_pages/index_<site>.json`; archivos en `data/raw_pages/<site>/<slug>.html/.md`

---

## Sistema Multi-Sitio y Estrategias

### Arquitectura de Estrategias

El sistema utiliza el **Strategy Pattern** para manejar diferentes sitios de forma modular y extensible. Cada sitio puede tener su propia estrategia que encapsula toda la l√≥gica espec√≠fica, permitiendo que el c√≥digo gen√©rico funcione con cualquier sitio.

### C√≥mo Funciona

1. **Registro de Estrategias**: Las estrategias se registran en `crawler/strategies/__init__.py` mapeando dominios a clases de estrategia.

2. **Selecci√≥n Autom√°tica**: Cuando se necesita scrapear una URL, el sistema:
   - Obtiene el dominio de la URL
   - Busca una estrategia espec√≠fica en el registro
   - Si no encuentra, usa `GenericStrategy` como fallback

3. **Delegaci√≥n**: El c√≥digo gen√©rico (como `WebScraper` y `ExtractionService`) delega toda la l√≥gica espec√≠fica a la estrategia:
   - Configuraci√≥n de Crawl4AI
   - Tipo de paginaci√≥n (din√°mica vs tradicional)
   - Extracci√≥n de datos espec√≠ficos (ej: "concursos anteriores")
   - Nombre del organismo

### Flujo de Selecci√≥n de Estrategia

```
URL ingresada
    ‚Üì
get_strategy_for_url(url)
    ‚Üì
Extraer dominio (ej: "anid.cl")
    ‚Üì
Buscar en STRATEGY_REGISTRY
    ‚Üì
¬øEncontrada? ‚Üí Usar estrategia espec√≠fica
    ‚Üì
¬øNo encontrada? ‚Üí Usar GenericStrategy
```

### Separaci√≥n de Responsabilidades

- **C√≥digo Gen√©rico**: `WebScraper`, `ExtractionService`, `GenericStrategy`
  - No contiene l√≥gica espec√≠fica de ning√∫n sitio
  - Funciona con cualquier estrategia que implemente la interfaz

- **C√≥digo Espec√≠fico**: `ANIDStrategy`, `AnidPagination`, `AnidExtractor`
  - Contiene TODA la l√≥gica espec√≠fica de ANID
  - Est√° completamente aislado en m√≥dulos espec√≠ficos
  - No interfiere con otros sitios

---

## C√≥mo Agregar un Nuevo Sitio

Esta secci√≥n explica paso a paso c√≥mo agregar soporte para un nuevo sitio al sistema.

### Paso 1: Analizar Estructura del Sitio

Antes de implementar, analiza el sitio objetivo:

1. **Tipo de Paginaci√≥n**:
   - ¬øUsa paginaci√≥n din√°mica (JavaScript/AJAX)? ‚Üí Requiere estrategia espec√≠fica
   - ¬øUsa enlaces HTML tradicionales? ‚Üí Puede usar `GenericStrategy`

2. **Estructura de Listado**:
   - ¬øC√≥mo se muestran los concursos en la p√°gina principal?
   - ¬øQu√© selectores CSS se usan?
   - ¬øRequiere espera especial para contenido din√°mico?

3. **Estructura de P√°ginas Individuales**:
   - ¬øD√≥nde est√° el nombre del concurso? (`<title>`, `<h1>`, etc.)
   - ¬øD√≥nde est√°n las fechas? (patrones espec√≠ficos, clases CSS)
   - ¬øHay informaci√≥n adicional estructurada?

4. **"Concursos Anteriores" o Similar**:
   - ¬øEl sitio tiene una secci√≥n de versiones anteriores?
   - ¬øC√≥mo se estructura esta informaci√≥n?
   - ¬øQu√© selectores CSS se usan?

### Paso 2: Decidir si Necesitas Estrategia Espec√≠fica

**Usa `GenericStrategy` (sin crear estrategia espec√≠fica) si**:
- El sitio usa paginaci√≥n tradicional (enlaces HTML)
- La estructura es est√°ndar (HTML com√∫n)
- No tiene secci√≥n de "concursos anteriores"
- La configuraci√≥n b√°sica de Crawl4AI es suficiente

**Crea estrategia espec√≠fica si**:
- El sitio requiere paginaci√≥n din√°mica (JavaScript)
- Tiene estructura √∫nica que requiere l√≥gica especial
- Tiene secci√≥n de "concursos anteriores" o similar
- Requiere configuraci√≥n espec√≠fica de Crawl4AI

### Paso 3: Crear Estrategia Espec√≠fica (si es necesario)

Si necesitas una estrategia espec√≠fica, crea `crawler/strategies/tu_sitio_strategy.py`:

```python
from crawler.strategies.base_strategy import ScrapingStrategy
from typing import List, Dict, Any
from crawl4ai import AsyncWebCrawler

class TuSitioStrategy(ScrapingStrategy):
    """Estrategia espec√≠fica para tu sitio."""
    
    @property
    def site_name(self) -> str:
        return "tu-sitio.cl"
    
    @property
    def site_display_name(self) -> str:
        return "Tu Sitio"
    
    def get_crawler_config(self) -> Dict[str, Any]:
        """Configuraci√≥n espec√≠fica de Crawl4AI."""
        return {
            "wait_for": "css:.selector-especifico",  # Ajustar seg√∫n el sitio
            "wait_until": "domcontentloaded",
            "scan_full_page": True,
        }
    
    def supports_dynamic_pagination(self) -> bool:
        return True  # o False seg√∫n el tipo de paginaci√≥n
    
    async def scrape_with_pagination(
        self,
        url: str,
        max_pages: int,
        crawler: AsyncWebCrawler,
        base_config: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """Implementar l√≥gica de scraping con paginaci√≥n."""
        # Si usa paginaci√≥n din√°mica, crear TuSitioPagination
        # Si usa paginaci√≥n tradicional, usar GenericPagination
        pass
    
    def extract_previous_concursos(
        self,
        html: str,
        url: str
    ) -> List[Dict[str, Any]]:
        """Extraer 'concursos anteriores' si el sitio los tiene."""
        # Si el sitio no tiene esta funcionalidad, retornar []
        return []
    
    def get_organismo_name(self, url: str) -> str:
        return "Tu Organismo"
    
    def get_known_subdirecciones(self) -> Set[str]:
        """Retornar subdirecciones conocidas si aplica."""
        return set()
```

### Paso 4: Crear Paginaci√≥n Espec√≠fica (si es necesario)

Si el sitio requiere paginaci√≥n din√°mica, crea `crawler/pagination/tu_sitio_pagination.py`:

```python
from crawler.pagination.base_pagination import BasePagination
from typing import List, Dict, Any
from crawl4ai import AsyncWebCrawler

class TuSitioPagination(BasePagination):
    """Paginaci√≥n din√°mica espec√≠fica para tu sitio."""
    
    async def scrape_pages(
        self,
        url: str,
        max_pages: int,
        crawler: AsyncWebCrawler,
        config: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """Implementar l√≥gica de paginaci√≥n din√°mica."""
        # Ver ejemplo completo en crawler/pagination/anid_pagination.py
        pass
```

### Paso 5: Crear Extractor Espec√≠fico (si es necesario)

Si el sitio tiene "concursos anteriores" o informaci√≥n similar, crea `utils/extractors/tu_sitio_extractor.py`:

```python
from utils.extractors.base_extractor import BaseExtractor
from typing import List, Dict, Any
from bs4 import BeautifulSoup

class TuSitioExtractor(BaseExtractor):
    """Extractor espec√≠fico para tu sitio."""
    
    def extract_previous_concursos(
        self,
        html: str,
        url: str
    ) -> List[Dict[str, Any]]:
        """Extraer informaci√≥n de concursos anteriores."""
        # Ver ejemplo completo en utils/extractors/anid_extractor.py
        soup = BeautifulSoup(html, 'html.parser')
        # Implementar l√≥gica de extracci√≥n
        return []
```

### Paso 6: Registrar la Estrategia

En `crawler/strategies/__init__.py`, actualiza la funci√≥n `_register_all_strategies()`:

```python
def _register_all_strategies():
    try:
        from crawler.strategies.anid_strategy import ANIDStrategy
        register_strategy("anid.cl", ANIDStrategy)
        register_strategy("www.anid.cl", ANIDStrategy)
        
        # Agregar tu nueva estrategia
        from crawler.strategies.tu_sitio_strategy import TuSitioStrategy
        register_strategy("tu-sitio.cl", TuSitioStrategy)
        register_strategy("www.tu-sitio.cl", TuSitioStrategy)
    except ImportError:
        pass
```

### Paso 7: Configurar Sitio en `config/sites.py`

Agrega la configuraci√≥n del sitio en `SITE_CONFIGS`:

```python
SITE_CONFIGS = {
    # ... configuraciones existentes ...
    "tu-sitio.cl": {
        "display_name": "Tu Sitio",
        "organismo": "Tu Organismo",
        "crawler_config": {
            "wait_for": "css:.selector-especifico",
            "wait_until": "domcontentloaded",
            "scan_full_page": True,
        },
        "features": {
            "dynamic_pagination": True,  # o False
            "has_previous_concursos": True,  # o False
        },
        "known_subdirecciones": set()  # o conjunto de subdirecciones
    },
}
```

Tambi√©n actualiza `SEED_URLS` y `SITE_NAME_MAPPING`:

```python
SEED_URLS = {
    # ... URLs existentes ...
    "Tu Sitio": [
        "https://tu-sitio.cl/concursos/",
    ],
}

SITE_NAME_MAPPING = {
    # ... mapeos existentes ...
    "Tu Sitio": "tu-sitio.cl",
}
```

### Checklist de Implementaci√≥n

Al agregar un nuevo sitio, verifica:

- [ ] Estrategia creada e implementada (si es necesaria)
- [ ] Paginaci√≥n espec√≠fica creada (si requiere paginaci√≥n din√°mica)
- [ ] Extractor espec√≠fico creado (si tiene "concursos anteriores")
- [ ] Estrategia registrada en `crawler/strategies/__init__.py`
- [ ] Configuraci√≥n agregada en `config/sites.py`
- [ ] URLs semilla agregadas en `SEED_URLS`
- [ ] Mapeo de nombre agregado en `SITE_NAME_MAPPING`
- [ ] Verificado funcionamiento b√°sico (scraping de primera p√°gina)
- [ ] Verificado paginaci√≥n (si aplica)
- [ ] Verificado extracci√≥n de "concursos anteriores" (si aplica)
- [ ] Documentaci√≥n actualizada (esta secci√≥n)

### Ejemplo Completo: ANID

ANID es un ejemplo completo de estrategia espec√≠fica:

- **Estrategia**: `crawler/strategies/anid_strategy.py`
  - Usa `AnidPagination` para paginaci√≥n din√°mica
  - Usa `AnidExtractor` para "concursos anteriores"
  - Configuraci√≥n espec√≠fica de Crawl4AI

- **Paginaci√≥n**: `crawler/pagination/anid_pagination.py`
  - Maneja clicks en botones JavaScript
  - Espera inteligente de contenido AJAX
  - Detecci√≥n robusta de √∫ltima p√°gina

- **Extractor**: `utils/extractors/anid_extractor.py`
  - Extrae "Concursos anteriores" usando selectores JetEngine
  - L√≥gica mejorada de nombres y a√±os

- **Configuraci√≥n**: `config/sites.py`
  - Configuraci√≥n espec√≠fica de ANID
  - Subdirecciones conocidas

---

## Modelos de Datos

### Modelo `Concurso`

Estructura est√°ndar de un concurso.

**Campos Requeridos**:
```python
nombre: str                    # Nombre completo del concurso
organismo: str                 # ANID, MINEDUC, CNA, etc.
url: str                       # URL de origen
```

**Campos Opcionales Principales**:
```python
fecha_apertura: Optional[str]  # Texto original (ej: "10 de diciembre, 2025")
fecha_cierre: Optional[str]     # Texto original (ej: "19 de marzo, 2026 - 17:00")
financiamiento: Optional[str]  # Monto o tipo
estado: Optional[str]          # "Abierto" o "Cerrado" (calculado)
descripcion: Optional[str]      # Resumen breve
subdireccion: Optional[str]    # Subdirecci√≥n o √°rea
```

### Modelo `PrediccionConcurso`

Estructura de una predicci√≥n.

```python
es_mismo_concurso: bool        # Siempre True cuando se usa previous_concursos
fecha_predicha: Optional[str] # Fecha en formato YYYY-MM-DD o texto descriptivo
justificacion: str             # P√°rrafo conciso (sin razones_similitud/diferencias)
```

### Modelos de Batch

**`PrediccionConcursoBatchItem`**:
```python
concurso_url: str              # Identificador √∫nico del concurso
prediccion: PrediccionConcurso # Predicci√≥n individual
```

**`PrediccionBatchResponse`**:
```python
items: List[PrediccionConcursoBatchItem]  # Lista de predicciones
```

---

## Flujos de Procesamiento

### Flujo Principal: Extracci√≥n de Concursos

```
1. Usuario ingresa URLs en UI (main.py) ‚Äî ahora se selecciona **un solo sitio** por corrida para evitar mezclas de dominios.
   ‚Üì
2. ExtractionService.extract_from_urls()
   ‚îú‚îÄ‚Üí Fase 1: Scraping de p√°ginas principales (delegado a estrategia)
   ‚îÇ   ‚îú‚îÄ‚Üí ANID: `scrape_url_with_dynamic_pagination()` (JetEngine), detecci√≥n robusta de √∫ltima p√°gina por ausencia de bot√≥n ">".
   ‚îÇ   ‚îú‚îÄ‚Üí CentroEstudios: bypass de paginaci√≥n, una sola p√°gina, timeout corto y sin JS pesado.
   ‚îÇ   ‚îî‚îÄ‚Üí Otros sitios: paginaci√≥n tradicional o scraping simple.
   ‚îÇ   ‚îú‚îÄ‚Üí Limpiar markdown (clean_markdown_for_llm)
   ‚îÇ   ‚îî‚îÄ‚Üí Agrupar en batches (hasta 250,000 caracteres)
   ‚îÇ
   ‚îú‚îÄ‚Üí Fase 2: Extracci√≥n inicial con LLM
   ‚îÇ   ‚îú‚îÄ‚Üí Para cada batch:
   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚Üí LLMExtractor.extract_from_batch()
   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚Üí Construir prompt con Structured Outputs
   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚Üí Ajustar maxOutputTokens din√°micamente (m√≠nimo 12000 para batches grandes)
   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚Üí Llamar a Gemini API REST
   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚Üí **Si JSON truncado**: Aumentar tokens y reintentar autom√°ticamente (hasta 3 veces, hasta 32000)
   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚Üí Validar con Pydantic
   ‚îÇ   ‚îÇ   ‚îÇ
   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚Üí Validar cantidad extra√≠da
   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚Üí Si p√©rdida detectada: re-extraer con modelo m√°s potente
   ‚îÇ   ‚îÇ   ‚îÇ
   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚Üí Convertir a objetos Concurso
   ‚îÇ   ‚îÇ
   ‚îÇ   ‚îî‚îÄ‚Üí Validaci√≥n final de p√©rdida total
   ‚îÇ
   ‚îú‚îÄ‚Üí Fase 3: Scraping de p√°ginas individuales
   ‚îÇ   ‚îú‚îÄ‚Üí Extraer URLs √∫nicas de concursos
   ‚îÇ   ‚îú‚îÄ‚Üí WebScraper.scrape_url_simple() (concurrente; o bypass si la estrategia ya entrega el concurso √∫nico, p. ej. CentroEstudios)
   ‚îÇ   ‚îú‚îÄ‚Üí Guardar HTML/Markdown completos en cache local `data/raw_pages/<site>/...` (sin compresi√≥n) y actualizar √≠ndice por URL
   ‚îÇ   ‚îú‚îÄ‚Üí **OPTIMIZACI√ìN: Extracci√≥n determin√≠stica** (antes de LLM; 100% determinista si la estrategia lo define)
   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚Üí Extraer nombre desde <title>, og:title, <h1>
   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚Üí Extraer fechas desde patrones "Inicio:", "Cierre:"
   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚Üí Detectar suspendido desde URL o contenido
   ‚îÇ   ‚îî‚îÄ‚Üí Guardar en enriched_content (con deterministic_data)
   ‚îÇ
   ‚îú‚îÄ‚Üí Fase 4: Enriquecimiento con LLM
   ‚îÇ   ‚îú‚îÄ‚Üí Para cada batch de contenido enriquecido:
   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚Üí LLMExtractor.extract_from_batch()
   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚Üí **Preferir datos determin√≠sticos sobre LLM**
   ‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚Üí Si nombre determin√≠stico existe ‚Üí usarlo
   ‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚Üí Si fechas determin√≠sticas existen ‚Üí usarlas
   ‚îÇ   ‚îÇ   ‚îÇ       ‚îî‚îÄ‚Üí LLM solo completa campos faltantes
   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚Üí Actualizar: financiamiento, descripcion
   ‚îÇ
   ‚îú‚îÄ‚Üí Fase 5: Reintento de fechas (si faltan)
   ‚îÇ   ‚îú‚îÄ‚Üí Solo para concursos sin fecha_cierre
   ‚îÇ   ‚îî‚îÄ‚Üí Segundo intento focalizado con LLM
   ‚îÇ
   ‚îú‚îÄ‚Üí Fase 6: Post-procesamiento
   ‚îÇ   ‚îú‚îÄ‚Üí Normalizar fechas (parse_date)
   ‚îÇ   ‚îú‚îÄ‚Üí Calcular estado determin√≠sticamente (Abierto/Cerrado/Suspendido)
   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚Üí **NO se calcula por LLM, siempre determin√≠stico**
   ‚îÇ   ‚îî‚îÄ‚Üí Agregar metadatos (extraido_en, fuente)
   ‚îÇ
   ‚îî‚îÄ‚Üí Fase 7: Actualizaci√≥n de historial
       ‚îú‚îÄ‚Üí Extraer previous_concursos de p√°ginas individuales
       ‚îÇ   ‚îú‚îÄ‚Üí strategy.extract_previous_concursos(html, url)
       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚Üí ANID: AnidExtractor (selectores JetEngine)
       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚Üí CentroEstudios: no hay previous_concursos externos (lista vac√≠a)
       ‚îÇ   ‚îÇ   ‚îî‚îÄ‚Üí Otros: GenericExtractor (retorna [])
       ‚îÇ   ‚îú‚îÄ‚Üí Extracci√≥n mejorada de nombres (filtra "Ver m√°s", busca en atributos)
       ‚îÇ   ‚îî‚îÄ‚Üí Extracci√≥n mejorada de a√±os (desde nombre, fechas o URL)
       ‚îú‚îÄ‚Üí update_history() con enriched_content
       ‚îî‚îÄ‚Üí Guardar debug (save_debug_info_scraping)
       ‚îî‚îÄ‚Üí **Reparaci√≥n autom√°tica post-scrape**: si el historial queda con concursos incompletos, se ejecuta `repair_incomplete_concursos` sobre esas URLs usando cache HTML/MD (sin re-scrapear si no es necesario), marcando suspendidos por patr√≥n y completando nombre/fechas con LLM solo donde falte.
```

### Flujo de Predicci√≥n Masiva (con Batching y Reintentos)

```
1. Usuario ejecuta "Realizar Predicciones" en UI
   ‚Üì
2. PredictionService.generate_predictions()
   ‚îú‚îÄ‚Üí Cargar concursos del historial
   ‚îú‚îÄ‚Üí Filtrar: cerrados + con previous_concursos (no vac√≠o)
   ‚îî‚îÄ‚Üí Aplicar filtros adicionales (subdirecci√≥n, b√∫squeda)
   ‚Üì
3. Filtrar concursos no predecibles ANTES de crear batches
   ‚îú‚îÄ‚Üí Filtrar self_reference (marcar como no predecible con justificaci√≥n autom√°tica)
   ‚îú‚îÄ‚Üí Filtrar concursos sin previous_concursos (salvo sitios habilitados expl√≠citamente, e.g. CentroEstudios, que se predice de forma determinista)
   ‚îî‚îÄ‚Üí Resultado: lista de concursos predecibles
   ‚Üì
4. Agrupar en batches de exactamente 10 concursos predecibles
   ‚îú‚îÄ‚Üí Para cada batch:
   ‚îÇ   ‚îú‚îÄ‚Üí Preparar datos (concurso_dict + previous_concursos_info)
   ‚îÇ   ‚îÇ
   ‚îÇ   ‚îú‚îÄ‚Üí ConcursoPredictor.predict_from_previous_concursos_batch()
   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚Üí Construir prompt batch (lenguaje afirmativo, ejemplos)
   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚Üí Usar Structured Outputs (PrediccionBatchResponse)
   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚Üí maxOutputTokens: 12000 (para 10 concursos)
   ‚îÇ   ‚îÇ   ‚îÇ
   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚Üí **Reintentos autom√°ticos** (hasta 3 intentos):
   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚Üí Si error de parsing JSON:
   ‚îÇ   ‚îÇ       ‚îÇ   ‚îú‚îÄ‚Üí Log detallado con posici√≥n del error
   ‚îÇ   ‚îÇ       ‚îÇ   ‚îú‚îÄ‚Üí Delay incremental (2s, 4s, 6s)
   ‚îÇ   ‚îÇ       ‚îÇ   ‚îî‚îÄ‚Üí Reintentar con mismo prompt
   ‚îÇ   ‚îÇ       ‚îÇ
   ‚îÇ   ‚îÇ       ‚îî‚îÄ‚Üí Si agotados 3 intentos:
   ‚îÇ   ‚îÇ           ‚îú‚îÄ‚Üí Registrar error cr√≠tico en debug
   ‚îÇ   ‚îÇ           ‚îú‚îÄ‚Üí Guardar debug inmediatamente
   ‚îÇ   ‚îÇ           ‚îî‚îÄ‚Üí Detener ejecuci√≥n de predicciones
   ‚îÇ   ‚îÇ
   ‚îÇ   ‚îî‚îÄ‚Üí Procesar cada predicci√≥n del batch:
   ‚îÇ       ‚îú‚îÄ‚Üí Si fecha_predicha es None ‚Üí llm_rejected
   ‚îÇ       ‚îú‚îÄ‚Üí Validar fecha (no pasada, no >1 a√±o futuro)
   ‚îÇ       ‚îî‚îÄ‚Üí Guardar predicci√≥n v√°lida
   ‚îÇ
   ‚îî‚îÄ‚Üí Continuar con siguiente batch
   ‚Üì
5. Guardar resultados
   ‚îú‚îÄ‚Üí save_predictions() ‚Üí predictions_{site}.json
   ‚îú‚îÄ‚Üí save_unpredictable_concursos() ‚Üí unpredictable_{site}.json
   ‚îî‚îÄ‚Üí save_debug_info_predictions() ‚Üí debug/predictions/
```

### Cache de p√°ginas individuales (HTML/Markdown)

- Se guarda el HTML crudo y el Markdown limpio de cada concurso en `data/raw_pages/<site>/<slug>.html/.md` (sin compresi√≥n).
- √çndice por sitio en `data/raw_pages/index_<site>.json` mapea URL ‚Üí rutas, tama√±os y timestamp.
- Escritura: solo en el scraping inicial y en cualquier re-scrape expl√≠cito; siempre sobrescribe la entrada previa para esa URL. Estrategias deterministas (ej. CentroEstudios) escriben siempre el HTML/MD completo del concurso √∫nico.
- Lectura prioritaria: procesos de reparaci√≥n/predicciones consultan primero el cache; solo si falta (o se decide rescrapear) se vuelve a scrapear y se sobreescribe.
- Clave de deduplicaci√≥n: combinaci√≥n sitio + URL, manteniendo la l√≥gica multi-sitio intacta.

### Flujo de Rotaci√≥n de API Keys

```
1. LLMExtractor/Predictor llama a Gemini API REST
   ‚Üì
2. requests.post() a Gemini API endpoint
   ‚Üì
3. Si error 429 (quota exceeded):
   ‚îú‚îÄ‚Üí _handle_quota_error()
   ‚îÇ   ‚îú‚îÄ‚Üí Marcar key actual como agotada
   ‚îÇ   ‚îú‚îÄ‚Üí Extraer retry_after del error response
   ‚îÇ   ‚îî‚îÄ‚Üí Rotar a siguiente key disponible
   ‚îÇ
   ‚îî‚îÄ‚Üí Reintentar llamada (hasta max_retries)
```

---

## Manejo de Errores y Reintentos

### Estrategia General

1. **Capturar errores espec√≠ficos**: No usar `except Exception` gen√©rico
2. **Logging detallado**: Incluir contexto y stack trace
3. **Reintentos autom√°ticos**: Para errores recuperables (parsing JSON, timeouts)
4. **Recuperaci√≥n cuando sea posible**: Rotaci√≥n de API keys, re-extracci√≥n
5. **Propagaci√≥n apropiada**: Dejar que errores cr√≠ticos se propaguen

### Reintentos Autom√°ticos en Predicciones

**Implementaci√≥n**: `llm/predictor.py` ‚Üí `predict_from_previous_concursos_batch()`

**Cu√°ndo se activa**:
- Error de parsing JSON (`json.JSONDecodeError`, `ValueError`)
- Errores de conexi√≥n o timeout (no cr√≠ticos)

**Comportamiento**:
- **M√°ximo 3 intentos** por batch
- **Delay incremental**: 2s, 4s, 6s entre intentos
- **Logging detallado**: Posici√≥n exacta del error JSON, primeros 500 chars de respuesta
- **Si agotados 3 intentos**:
  - Error marcado como cr√≠tico
  - Debug guardado inmediatamente
  - Ejecuci√≥n de predicciones detenida
  - Mensaje claro indicando posible causa (truncamiento por tokens)

**L√≠mites de tokens din√°micos**:
- Predicciones individuales: 2000 tokens
- Predicciones en batch: 12000 tokens (para 10 concursos con justificaciones completas)
- Extracci√≥n de batches: Ajuste din√°mico seg√∫n tama√±o (m√≠nimo 12000, m√°ximo 32000)
  - C√°lculo: ~800 tokens por concurso √ó factor de seguridad 1.5
  - Si se detecta truncamiento: aumenta autom√°ticamente (duplica, hasta 32000) y reintenta

### Errores Comunes y Manejo

#### Error 429 (Quota Exceeded)

**D√≥nde**: `llm/gemini_client.py`, `llm/extractors/llm_extractor.py`, `llm/predictor.py`

**Manejo**:
- Detectar tipo de rate limit (temporal vs diario)
- Rotar a siguiente API key disponible
- Esperar `retry_after` si es rate limit temporal
- Logging sin exponer API keys completas

#### Error de Parsing JSON / JSON Truncado

**D√≥nde**: 
- `llm/predictor.py` ‚Üí `_parse_prediction_batch_response()` (predicciones)
- `llm/extractors/llm_extractor.py` ‚Üí `_call_llm_with_retry()` (extracci√≥n)

**Manejo en Predicciones**:
- **Reintentos autom√°ticos** (hasta 3 intentos)
- Log detallado con posici√≥n exacta del error
- Mensaje sugerente si es truncamiento por tokens
- Si persiste: error cr√≠tico, guardar debug, detener ejecuci√≥n

**Manejo en Extracci√≥n (NUEVO)**:
- **Detecci√≥n autom√°tica de truncamiento**: Verifica `finishReason == "MAX_TOKENS"` o JSON incompleto
- **Aumento autom√°tico de tokens**: Duplica `maxOutputTokens` (hasta 32000, l√≠mite m√°ximo)
- **Reintento autom√°tico**: Hasta 3 aumentos de tokens con reintentos autom√°ticos
- **Sin p√©rdida de datos**: El sistema garantiza que no se aceptan respuestas truncadas
- Si se alcanza el l√≠mite m√°ximo (32000) y a√∫n est√° truncado: excepci√≥n clara indicando que el batch es demasiado grande

**Nota**: Con Structured Outputs de Gemini, estos errores son raros pero posibles si el l√≠mite de tokens es insuficiente. El sistema ahora los maneja autom√°ticamente.

#### Error de Scraping

**D√≥nde**: `crawler/scraper.py`, `services/extraction_service.py`

**Manejo**:
- Continuar con siguiente URL
- Registrar error en debug
- No detener el proceso completo

### Logging de Errores

Siempre incluir:
- Contexto (URL, p√°gina, batch, etc.)
- Stack trace para errores inesperados
- Informaci√≥n de recuperaci√≥n si aplica
- Emojis para identificaci√≥n r√°pida (‚ùå errores, ‚ö†Ô∏è warnings)

**Tracking de Errores**:
- Errores registrados en `debug_info` con informaci√≥n completa
- Incluyen timestamp, contexto, tipo, mensaje y traceback
- Se guardan en archivos de debug para an√°lisis posterior

---

## Extracci√≥n Determin√≠stica vs LLM

### Estrategia: "Determin√≠stico Primero, LLM como Fallback"

El sistema utiliza una estrategia de **extracci√≥n determin√≠stica primero, LLM como fallback** para optimizar costos y tiempo. Solo se llama al LLM cuando la extracci√≥n determin√≠stica no puede obtener los datos necesarios.

### ¬øCu√°ndo se llama al LLM?

El LLM (Gemini API) se llama **SOLO** en los siguientes casos:

#### 1. Extracci√≥n Inicial desde Listados (Fase 2)
- **Cu√°ndo**: Al procesar batches de p√°ginas de listado de concursos
- **Por qu√©**: Necesita extraer m√∫ltiples concursos de una sola p√°gina
- **Qu√© extrae**: Nombre, fechas, organismo, financiamiento, descripci√≥n, subdirecci√≥n
- **Optimizaci√≥n**: Si se encontraron datos determin√≠sticos, se prefieren sobre los del LLM

#### 2. Enriquecimiento de P√°ginas Individuales (Fase 4)
- **Cu√°ndo**: Despu√©s de scrapear p√°ginas individuales de cada concurso
- **Por qu√©**: Completar informaci√≥n faltante (nombre, fechas, descripci√≥n, etc.)
- **Optimizaci√≥n**: 
  - Si el nombre se extrajo determin√≠sticamente, se usa ese
  - Si las fechas se extrajeron determin√≠sticamente, se usan esas
  - El LLM solo completa campos que faltan

#### 3. Reintento de Fechas (Fase 5)
- **Cu√°ndo**: Si un concurso a√∫n no tiene `fecha_cierre` despu√©s del enriquecimiento
- **Por qu√©**: Segundo intento focalizado solo en fechas
- **Optimizaci√≥n**: Solo se llama si realmente faltan fechas

#### 4. Reparaci√≥n de Concursos Incompletos
- **Cu√°ndo**: Al usar el bot√≥n "Revisar y reparar concursos incompletos"
- **Por qu√©**: Intentar completar datos faltantes de concursos problem√°ticos
- **Optimizaci√≥n**: Usa extracci√≥n determin√≠stica primero

### ¬øCu√°ndo NO se llama al LLM?

1. **Si se extrajeron nombre y fechas determin√≠sticamente**: El LLM se llama pero sus resultados se complementan con los determin√≠sticos
2. **Si el concurso est√° suspendido y se detect√≥ por URL**: No se scrapea ni se llama al LLM
3. **Si el concurso est√° suspendido y se detect√≥ por contenido**: Se marca como suspendido sin necesidad de LLM

### Extracci√≥n Determin√≠stica Implementada

#### Nombre del Concurso
- Se extrae desde:
  - Tag `<title>` del HTML (removiendo sufijos como " - ANID")
  - Meta tag `og:title`
  - Primer `<h1>` en el contenido principal
  - Primer heading en Markdown (`#` o `##`)

#### Fechas de Apertura y Cierre
- Se buscan patrones en el Markdown:
  - "Inicio: " o "Apertura: " seguido de fecha
  - "Cierre: " o "Fecha de cierre: " seguido de fecha
  - Variaciones con `**` (markdown bold)

#### Estado Suspendido
- Se detecta desde:
  - URL que contiene "concurso-suspendido"
  - Texto "concurso suspendido" en HTML/Markdown

### Estad√≠sticas de Optimizaci√≥n

En un scraping t√≠pico de ANID con ~400 concursos:
- **Sin optimizaci√≥n**: ~400-800 llamadas al LLM (dependiendo de batches)
- **Con optimizaci√≥n**: ~200-400 llamadas al LLM (reducci√≥n del 50% aproximadamente)

La reducci√≥n real depende de:
- Cu√°ntos concursos tienen fechas en formato est√°ndar
- Cu√°ntos concursos tienen nombre en `<title>` o `og:title`
- Cu√°ntos concursos est√°n suspendidos

### Nota sobre Crawl4AI

**Crawl4AI NO es una llamada al LLM**. Es un proceso de scraping web tradicional que:
- Obtiene el contenido HTML de las p√°ginas
- Lo convierte a Markdown
- No realiza llamadas a APIs de LLM

---

## Decisiones de Dise√±o

### 1. ¬øPor qu√© Pydantic?

- Validaci√≥n autom√°tica de tipos
- Serializaci√≥n/deserializaci√≥n JSON
- Documentaci√≥n integrada
- Facilita desarrollo y debugging

### 2. ¬øPor qu√© Separar Cliente API de Extractor?

- **Cliente API**: Solo comunicaci√≥n, f√°cil de testear con mocks
- **Extractor**: L√≥gica de negocio, puede cambiar sin afectar cliente
- Permite cambiar de LLM sin reescribir toda la l√≥gica

### 3. ¬øPor qu√© Service Layer?

- Separa UI de l√≥gica de negocio
- Facilita testing
- Permite reutilizar l√≥gica en otros contextos (CLI, API, etc.)

### 4. ¬øPor qu√© Batches en Extracci√≥n?

- Reduce n√∫mero de llamadas al LLM
- Optimiza costo y tiempo
- Mejora contexto para el LLM (ve m√∫ltiples p√°ginas juntas)
- L√≠mite de 250,000 caracteres por batch (configurable)

### 5. ¬øPor qu√© Batching en Predicciones?

**Problema**: Procesar 300 concursos individualmente = 300 llamadas al LLM (lento, costoso, riesgo de rate limits).

**Soluci√≥n**: Agrupar en batches de 10 concursos por llamada.

- **Eficiencia**: Reduce ~10x el n√∫mero de requests (300 ‚Üí ~30 llamadas)
- **Precisi√≥n**: Cada concurso se analiza de forma independiente dentro del batch
- **Tokens optimizados**: 12000 tokens para batches (vs 2000 para individuales)
- **Batches consistentes**: Filtrado previo garantiza batches de exactamente 10 concursos
- **Reintentos autom√°ticos**: Hasta 3 intentos para errores de parsing JSON
- **Filtrado previo**: Detecta `self_reference` antes del LLM (ahorra tokens)

**Balance tokens/precisi√≥n**:
- 10 concursos por batch es punto √≥ptimo entre eficiencia y capacidad de an√°lisis
- Cada concurso mantiene su bloque propio con datos completos
- LLM recibe instrucciones expl√≠citas para an√°lisis independiente

### 6. ¬øPor qu√© Rotaci√≥n de API Keys?

- Maneja l√≠mites de cuota autom√°ticamente
- Permite escalar sin intervenci√≥n manual
- Tracking de uso por key con estad√≠sticas detalladas
- Persistencia en archivo JSON seguro

### 7. ¬øPor qu√© Structured Outputs?

- Garantiza JSON v√°lido (elimina necesidad de reparar JSON)
- Fuerza al LLM a usar nombres de campos exactos del schema
- Reduce errores de parsing y mapeo
- Permite excluir campos calculados del schema enviado al LLM

### 8. ¬øPor qu√© Archivos de Debug?

- Facilita debugging r√°pido de ejecuciones
- Incluye toda la informaci√≥n relevante en un solo archivo
- Permite revisar contenido raw y procesado
- √ötil para auditor√≠a y mejora continua

### 9. ¬øPor qu√© Detecci√≥n y Recuperaci√≥n Autom√°tica de P√©rdida de Datos?

- **Problema**: El LLM puede omitir concursos en batches grandes
- **Soluci√≥n**: Sistema de detecci√≥n multi-nivel
  - Por batch: Detecta cuando se extraen menos de 4-5 concursos por p√°gina
  - Total: Valida al final que el promedio sea razonable
- **Recuperaci√≥n autom√°tica**: Re-extrae con modelo m√°s potente cuando se detecta p√©rdida
- **Beneficios**: Mayor confiabilidad sin intervenci√≥n manual, usa modelo m√°s potente solo cuando es necesario

### 10. ¬øPor qu√© Extracci√≥n Determin√≠stica?

- **Problema**: Llamar al LLM para cada concurso es costoso y lento
- **Soluci√≥n**: Extraer datos determin√≠sticamente cuando est√°n en formato est√°ndar
  - Nombre desde `<title>` o `og:title` (muy com√∫n)
  - Fechas desde patrones "Inicio:", "Cierre:" (est√°ndar en ANID)
  - Estado suspendido desde URL o contenido
- **Beneficios**: 
  - Reducci√≥n del ~50% en llamadas al LLM
  - Menor costo y tiempo de procesamiento
  - Mayor precisi√≥n (datos determin√≠sticos son m√°s confiables)
- **Fallback**: Si no se pueden extraer determin√≠sticamente, se usa LLM

### 11. ¬øPor qu√© el Estado NO se calcula por LLM?

- **Raz√≥n**: El estado ("Abierto", "Cerrado", "Suspendido", "Pr√≥ximo") se puede calcular determin√≠sticamente
- **C√°lculo determin√≠stico**:
  - Si `fecha_cierre < hoy` ‚Üí "Cerrado"
  - Si `fecha_cierre >= hoy` ‚Üí "Abierto"
  - Si `fecha_apertura > hoy` ‚Üí "Pr√≥ximo"
  - Si URL contiene "concurso-suspendido" o contenido dice "suspendido" ‚Üí "Suspendido"
- **Beneficios**: 
  - Elimina carga cognitiva innecesaria del LLM
  - Reduce costos (no se env√≠a campo `estado` en el schema)
  - Mayor precisi√≥n (siempre actualizado seg√∫n fecha actual)
- **Implementaci√≥n**: El campo `estado` se elimina del schema JSON enviado al LLM

---

## Manejo de M√∫ltiples Versiones de Predicciones

### Comportamiento Actual

El sistema actualmente guarda predicciones en `utils/file_manager.py` mediante la funci√≥n `save_predictions()`.

**L√≥gica de deduplicaci√≥n:**
- Las predicciones se identifican √∫nicamente por `concurso_url`
- Si ya existe una predicci√≥n para una URL, **NO se agrega una nueva predicci√≥n**
- El sistema evita duplicados bas√°ndose √∫nicamente en la URL del concurso

### Escenario: Predicci√≥n 2026 vs Versi√≥n 2024

**Pregunta:** ¬øQu√© pasar√≠a si ya se predijo una versi√≥n "2026" para un concurso de fecha "2025", y el sistema encuentra la versi√≥n "2024" y trata de realizar una predicci√≥n?

**Respuesta:**

1. **Si la versi√≥n 2024 y 2026 comparten la misma URL:**
   - El sistema **NO crear√° una nueva predicci√≥n** para la versi√≥n 2024
   - La predicci√≥n existente para 2026 se mantendr√°
   - La versi√≥n 2024 ser√° ignorada en el proceso de guardado

2. **Si la versi√≥n 2024 y 2026 tienen URLs diferentes:**
   - El sistema **S√ç crear√° una nueva predicci√≥n** para la versi√≥n 2024
   - Ambas predicciones coexistir√°n en el archivo de predicciones
   - Esto podr√≠a resultar en m√∫ltiples predicciones para el mismo concurso (diferentes versiones)

### Limitaciones Actuales

1. **No hay detecci√≥n de versiones del mismo concurso:**
   - El sistema no identifica que "Concurso X 2024" y "Concurso X 2026" son versiones del mismo concurso
   - Solo se basa en la URL para evitar duplicados

2. **No hay gesti√≥n de versiones m√∫ltiples:**
   - Si un concurso tiene m√∫ltiples versiones con URLs diferentes, se crear√°n m√∫ltiples predicciones
   - No hay l√≥gica para mantener solo la predicci√≥n m√°s reciente o relevante

3. **No hay validaci√≥n de coherencia temporal:**
   - El sistema no valida si una predicci√≥n para 2024 tiene sentido cuando ya existe una para 2026
   - No hay l√≥gica para priorizar predicciones m√°s recientes

### Mejoras Futuras Sugeridas

#### Opci√≥n 1: Detecci√≥n de Versiones por Nombre
- Implementar l√≥gica de similitud de nombres (ya existe en `utils/concurso_similarity.py`)
- Si dos concursos tienen nombres similares (>80% similitud), tratarlos como versiones del mismo concurso
- Mantener solo la predicci√≥n m√°s reciente

#### Opci√≥n 2: Identificador de Concurso Base
- Agregar un campo `concurso_base_id` que identifique el concurso independientemente del a√±o
- Normalizar nombres removiendo a√±os (ej: "Concurso X 2024" ‚Üí "Concurso X")
- Agregar l√≥gica para mantener solo una predicci√≥n activa por `concurso_base_id`

#### Opci√≥n 3: Sistema de Versiones Expl√≠cito
- Agregar un campo `version` o `a√±o` a las predicciones
- Permitir m√∫ltiples predicciones para el mismo concurso, pero marcadas con su versi√≥n
- Implementar UI para mostrar todas las versiones de un concurso

#### Opci√≥n 4: Validaci√≥n Temporal
- Antes de guardar una nueva predicci√≥n, verificar si existe una predicci√≥n m√°s reciente
- Si existe una predicci√≥n para un a√±o futuro (ej: 2026), no permitir predicciones para a√±os anteriores (ej: 2024)
- O permitir ambas pero marcar la m√°s antigua como "obsoleta"

**Ubicaci√≥n de l√≥gica actual:** `utils/file_manager.py`, funci√≥n `save_predictions()`, l√≠neas 561-567

---

## Gu√≠a para Desarrollo

### Al Modificar C√≥digo

1. **Leer el archivo completo** antes de modificar
2. **Entender el contexto** del cambio
3. **Mantener el estilo** existente
4. **Actualizar documentaci√≥n** si es necesario
5. **Verificar imports** y dependencias
6. **Eliminar c√≥digo obsoleto** en lugar de comentarlo

### Al Agregar Funcionalidad

1. **Identificar el m√≥dulo correcto** seg√∫n responsabilidad
2. **Seguir patrones existentes** en ese m√≥dulo
3. **Agregar logging** apropiado
4. **Manejar errores** robustamente
5. **Implementar reintentos** si es apropiado
6. **Actualizar esta documentaci√≥n** si es necesario

### C√≥mo Agregar un Nuevo Campo al Modelo Concurso

1. **Editar `models/concurso.py`**: Agregar campo al modelo
2. **Actualizar `llm/prompts.py`**: Agregar instrucciones para extraer el campo
3. **Actualizar validaci√≥n** si es necesario
4. **Actualizar mapeo** en `llm/extractors/llm_extractor.py`

### C√≥mo Agregar Soporte para un Nuevo Sitio Web

1. **Identificar tipo de paginaci√≥n**: Din√°mica, tradicional, o sin paginaci√≥n
2. **Si es paginaci√≥n din√°mica**: Agregar l√≥gica en `scraper.py`
3. **Identificar estructura de p√°ginas individuales**
4. **Actualizar prompts** si el sitio tiene formato diferente
5. **Agregar URL semilla** en `config.py`

---

## Extensibilidad

### Agregar un Nuevo LLM

1. Crear nuevo cliente en `llm/`
2. Crear extractor que use el nuevo cliente
3. Modificar `ExtractionService` para aceptar tipo de extractor

### Agregar un Nuevo Formato de Exportaci√≥n

1. Agregar funci√≥n en `utils/file_manager.py`
2. Exportar en `utils/__init__.py`
3. Agregar opci√≥n en UI (`main.py`)

---

## Convenciones de C√≥digo

### Nombres

- **snake_case** para archivos, m√≥dulos, funciones y variables
- **PascalCase** para clases
- **UPPER_CASE** para constantes

### Imports

Orden:
1. Standard library
2. Third-party
3. Local application

### Documentaci√≥n

- **Docstrings** en todas las clases y funciones p√∫blicas
- Formato Google style

### Logging

- Usar `logging.getLogger(__name__)` en cada m√≥dulo
- Niveles apropiados: DEBUG, INFO, WARNING, ERROR

---

## Recursos y Referencias

- **Configuraci√≥n**: Ver `config.py` para todas las opciones
- **Logs**: Revisar logs para debugging
- **Ejemplos**: Ver `models/concurso.py` para ejemplos de datos

---

## Preparaci√≥n para Despliegue en AWS (modo pr√°ctica)

- Objetivo: despliegue r√°pido en EC2 con Docker y tareas programadas simples (cron) para ANID.
- Separaci√≥n de vistas (recomendado):
  - **Vista P√∫blica/Visualizaci√≥n**: lista unificada de todos los concursos (todas las fuentes), con filtros avanzados (estado, organismo, subdirecci√≥n, b√∫squeda, fecha de apertura/cierre, fuente, ‚Äúincompletos‚Äù), sin acciones destructivas.
  - **Vista Administraci√≥n**: ejecutar scraping manual, ejecutar predicciones manuales, limpiar historiales/predicciones, agregar concursos manuales. Acceso √∫nico (sin hardening estricto para este caso de pr√°ctica).
- Automatizaciones m√≠nimas:
  - Cron diario en EC2: script `scripts/run_daily_anid.sh` (usa `scripts/daily_anid.py`) que hace scrape ANID (m√°x 2 p√°ginas) y luego predicciones ANID.
  - Se encapsula en un √∫nico script diario (scrape‚Üírepair impl√≠cito‚Üípredict).
- Dockerizaci√≥n b√°sica:
  - `Dockerfile` multietapa simple (builder + runtime slim), instala dependencias y expone `streamlit run main.py --server.port 8501 --server.address 0.0.0.0`.
  - `docker-compose.yml` (opcional) para desarrollo local (servicio app + volumen `data/` persistente).
  - Variables m√≠nimas por entorno: `API_KEYS_PATH`, `DATA_DIR` (montada en volumen), `PORT`.
- Despliegue en EC2 (m√≠nimo):
  - Instalar Docker + docker-compose.
  - Copiar `.env` (claves Gemini), montar `data/` en volumen persistente.
  - Abrir puerto 8501 o mapear a 80/443 detr√°s de un ALB/Nginx (opcional).
- Consideraciones de estabilidad:
  - Locks por sitio ya existen; validar limpieza de locks en cron (stale 5 min).
  - Backups simples: snapshot peri√≥dico de `data/` (history, predictions, raw_pages, debug).
  - Monitoreo ligero: logs stdout de Docker + rotaci√≥n (log-driver json-file con `max-size`/`max-file`).
- Pendientes para futura producci√≥n (no cr√≠tico para la pr√°ctica):
  - Autenticaci√≥n b√°sica en vista de administraci√≥n.
  - HTTPS (ALB o Nginx con cert).
  - Healthcheck simple (`streamlit` no expone; a√±adir endpoint lightweight en el futuro).
  - M√©tricas (Prometheus/OpenTelemetry) opcional.

## Cambios Recientes

### v4.6 - Preparaci√≥n AWS y separaci√≥n de vistas (2025-12-17)

- A√±adida secci√≥n de despliegue b√°sico en AWS (EC2 + Docker + cron diario ANID con predicci√≥n autom√°tica).
- Recomendaci√≥n de separar vistas: una de visualizaci√≥n (solo lectura, todos los concursos con filtros) y otra de administraci√≥n (scraping, predicciones manuales, limpieza, alta manual).
- Notas operativas m√≠nimas: cron diario, backup de `data/`, uso de locks existentes, logging sencillo.

### v4.5 - Concursos Manuales en pesta√±a dedicada (2025-12-17)

- Nueva pesta√±a de UI ‚Äúüìù Concursos Manuales‚Äù: lista todos los concursos guardados en `manual.local` y sus predicciones deterministas.
- Formulario con validaci√≥n estricta (YYYY-MM-DD) y regla de negocio: la fecha de cierre debe ser posterior a la de apertura; no se restringe pasado/futuro.
- Cada alta manual guarda en historial `manual.local`, cachea el contenido (markdown/html b√°sico del formulario) y asigna predicci√≥n autom√°tica (+1 a√±o desde la fecha de apertura), sin usar el flujo de predicciones ni el LLM.
- El flujo general de predicciones excluye los concursos manuales; su predicci√≥n se genera al momento de crearlos.

### v4.4 - Estrategia CentroEstudios y predicci√≥n habilitada (2025-12-17)

- Estrategia espec√≠fica `centro_estudios_strategy.py`: sin paginaci√≥n, sin LLM, timeout corto y JS trivial; extracci√≥n determinista del bloque ‚ÄúConvocatoria actual (FONIDE NN)‚Äù con nombre adaptable (FONIDE 16/17/‚Ä¶), fecha de consultas (apertura) y fecha de postulaciones (cierre).
- Scraper salta waits pesados cuando la estrategia es CentroEstudios (evita demoras >1 min).
- Predicciones: UI permite concursos cerrados sin `previous_concursos` cuando el dominio est√° habilitado (CentroEstudios) para permitir predicci√≥n anual determinista.
- Cache e historial guardan siempre HTML/MD completos del concurso √∫nico de CentroEstudios.
- UI de scraping ahora forza **un solo sitio por corrida** y el servicio filtra URLs de dominios distintos para evitar mezclas.
- Locks de scraping: se consideran obsoletos a los 5 minutos (`stale_seconds=300`) para limpiar locks viejos autom√°ticamente.
- **Reparaci√≥n autom√°tica post-scrape**: tras cada extracci√≥n, si quedan concursos incompletos en el historial, se ejecuta `repair_incomplete_concursos` sobre esas URLs, usando cache HTML/MD y evitando re-scrapear cuando es posible.

### v4.3 - Resiliencia ante concurrencia scraping/predicci√≥n (2025-12-16)

- **Locks por sitio/operaci√≥n**: `utils/lock_manager.py` con lockfiles en `data/locks`.
- **Scraping**: `ExtractionService.extract_from_urls` adquiere lock `scrape` por sitio; limpia locks obsoletos y evita ejecuciones simult√°neas.
- **Predicciones**: `PredictionService.generate_predictions` detecta lock `scrape` activo y devuelve mensaje de espera en lugar de fallar.
- **Objetivo**: Evitar crashes cuando se lanzan predicciones mientras hay scraping en curso.

### v4.2 - Predicciones sin campo de confianza (2025-12-16)

- **Eliminado**: Campo y l√≥gica de `confianza` en predicciones.
- **Simplificado**: Prompts y modelos (`PrediccionConcurso`, batches) sin confianza.
- **Servicios**: `prediction_service` ya no calcula ni solicita confianza a LLM; solo valida fechas y justificaciones.
- **Documentaci√≥n**: ARQUITECTURA.md actualizado para reflejar flujo sin confianza.

### v4.1 - Cache completo de p√°ginas individuales (2025-12-16)

- Guardado de HTML/Markdown sin compresi√≥n para cada URL de concurso (`data/raw_pages/<site>/<slug>.html/.md`) con √≠ndice por sitio.
- Reparaciones/predicciones leen primero desde cache; cualquier re-scrape sobrescribe la entrada de esa URL.
- Mantiene claves por sitio+URL para respetar la arquitectura multi-sitio.
- Documentaci√≥n auditada y actualizada con la nueva pol√≠tica de cache.

### v4.0 - Sistema Multi-Sitio con Estrategias (2025-12-16)

- **Refactorizaci√≥n completa**: Sistema transformado de "extractor espec√≠fico de ANID" a "extractor gen√©rico de concursos gubernamentales"
- **Implementaci√≥n de Strategy Pattern**: 
  - Nuevo m√≥dulo `crawler/strategies/` con clases base y estrategias espec√≠ficas
  - `ANIDStrategy`: Encapsula toda la l√≥gica espec√≠fica de ANID
  - `GenericStrategy`: Fallback para sitios est√°ndar sin l√≥gica espec√≠fica
- **M√≥dulo de paginaci√≥n**: 
  - Nuevo m√≥dulo `crawler/pagination/` con clases base y espec√≠ficas
  - `AnidPagination`: Paginaci√≥n din√°mica espec√≠fica de ANID
  - `GenericPagination`: Paginaci√≥n tradicional para sitios est√°ndar
- **M√≥dulo de extractores**: 
  - Nuevo m√≥dulo `utils/extractors/` con clases base y espec√≠ficas
  - `AnidExtractor`: Extracci√≥n de "Concursos anteriores" espec√≠fica de ANID
  - `GenericExtractor`: Extractor gen√©rico (retorna lista vac√≠a)
- **Configuraci√≥n por sitio**: 
  - Nuevo m√≥dulo `config/` con `global_config.py` y `sites.py`
  - Configuraci√≥n centralizada por sitio en `config/sites.py`
  - `config.py` mantiene compatibilidad como wrapper
- **Refactorizaci√≥n de m√≥dulos existentes**:
  - `WebScraper`: Ahora usa estrategias, m√©todo `scrape_url_with_pagination()` gen√©rico
  - `ExtractionService`: Eliminada toda l√≥gica hardcodeada de ANID, usa estrategias
  - `main.py`: Usa configuraci√≥n centralizada para mapeo de sitios
- **Separaci√≥n total**: C√≥digo espec√≠fico de ANID completamente aislado en m√≥dulos espec√≠ficos
- **Documentaci√≥n completa**: Secci√≥n detallada "C√≥mo Agregar un Nuevo Sitio" en ARQUITECTURA.md
- **Extensibilidad**: Agregar nuevo sitio ahora requiere solo crear nueva clase Strategy

### v3.5 - Reintento Autom√°tico con Aumento de Tokens y Mejoras en Extracci√≥n (2025-12-16)

- **Agregado**: Reintento autom√°tico con aumento de tokens en extracci√≥n
  - Si el JSON est√° truncado, detecta autom√°ticamente (`finishReason == "MAX_TOKENS"` o JSON incompleto)
  - Aumenta `maxOutputTokens` autom√°ticamente (duplica, hasta 32000)
  - Reintenta hasta 3 veces con tokens aumentados
  - **Garantiza cero p√©rdida de datos**: No acepta respuestas truncadas
- **Mejorado**: Extracci√≥n de nombres en `previous_concursos`
  - Filtra textos gen√©ricos como "Ver m√°s", "Leer m√°s"
  - Busca en atributos `title` y `data-*` del link cuando el texto es gen√©rico
  - Prioriza m√∫ltiples fuentes para obtener el nombre real del concurso
- **Mejorado**: Extracci√≥n de a√±os en `previous_concursos`
  - Extrae a√±os desde m√∫ltiples fuentes: nombre, fecha_apertura, fecha_cierre, URL
  - Reduce casos de a√±os `null`
- **Mejorado**: Manejo de errores de estructura inv√°lida
  - Justificaciones detalladas que incluyen valores espec√≠ficos del LLM
  - Informaci√≥n completa en debug para diagn√≥stico
- **Agregado**: Detecci√≥n autom√°tica de √∫ltima p√°gina en paginaci√≥n
  - Verifica existencia del bot√≥n ">" (siguiente) antes y despu√©s de cada p√°gina
  - Si no existe, detecta autom√°ticamente la √∫ltima p√°gina y detiene el scraping
  - Evita intentos innecesarios de procesar p√°ginas inexistentes
- **Aumentado**: `maxOutputTokens` inicial para batches grandes
  - C√°lculo mejorado: ~800 tokens por concurso √ó factor 1.5
  - M√≠nimo de 12000 para batches grandes (antes 8000)
  - M√≠nimo de 20000 para batches >150000 caracteres

### v3.4 - Optimizaci√≥n de Batches y Aumento de Tokens (2025-12-16)

- **Mejorado**: Filtrado previo de concursos no predecibles antes de crear batches
  - Los self_reference se filtran ANTES de crear batches
  - Garantiza que cada batch tenga exactamente 10 concursos (excepto el √∫ltimo)
  - Mejora la optimizaci√≥n al mantener batches de tama√±o consistente
- **Aumentado**: `maxOutputTokens` para predicciones batch de 8000 a 12000
  - Proporciona m√°s espacio para justificaciones completas
  - Reduce riesgo de truncamiento en batches grandes
- **Documentado**: Actualizado flujo de predicci√≥n masiva en ARQUITECTURA.md

### v3.3 - Extracci√≥n Determin√≠stica y Optimizaciones (2025-12-16)

- **Agregado**: Extracci√≥n determin√≠stica de nombre del concurso
  - Desde `<title>`, `og:title`, `<h1>`, o primer heading en Markdown
  - Reduce llamadas al LLM cuando el nombre est√° disponible en metadatos
- **Agregado**: Extracci√≥n determin√≠stica de fechas
  - Desde patrones "Inicio:", "Cierre:" en Markdown
  - Reduce llamadas al LLM cuando las fechas est√°n en formato est√°ndar
- **Mejorado**: Preferencia de datos determin√≠sticos sobre LLM
  - Si se extrajeron determin√≠sticamente, se prefieren sobre los del LLM
  - El LLM solo completa campos faltantes
- **Eliminado**: C√°lculo de estado por LLM
  - El estado ahora se calcula siempre determin√≠sticamente desde fechas
  - Campo `estado` eliminado del schema JSON enviado al LLM
- **Documentado**: Secci√≥n completa sobre "Extracci√≥n Determin√≠stica vs LLM"
  - Explica cu√°ndo se llama al LLM y cu√°ndo no
  - Estad√≠sticas de optimizaci√≥n (~50% reducci√≥n en llamadas)
- **Documentado**: Manejo de m√∫ltiples versiones de predicciones
  - Comportamiento actual y limitaciones
  - Sugerencias para mejoras futuras

### v3.2 - Optimizaci√≥n de Tokens y Reintentos Autom√°ticos (2025-12-16)

- **Agregado**: L√≠mites de tokens din√°micos para predicciones
  - Predicciones individuales: 2000 tokens
  - Predicciones en batch: 8000 tokens (para acomodar 10 concursos con justificaciones completas)
- **Agregado**: Reintentos autom√°ticos en predicciones batch
  - Hasta 3 intentos para errores de parsing JSON
  - Delay incremental (2s, 4s, 6s) entre intentos
  - Logging detallado con posici√≥n exacta del error
  - Detenci√≥n controlada si agotados 3 intentos (guarda debug antes de detener)
- **Mejorado**: Mensajes de error m√°s informativos
  - Sugerencias cuando el error es por truncamiento de tokens
  - Contexto completo para debugging

### v3.1 - Batching de Predicciones (2025-12-16)

- **Agregado**: Sistema de batching para predicciones masivas
  - `PredictionService.generate_predictions()` agrupa concursos en batches de 10
  - Nuevo m√©todo `ConcursoPredictor.predict_from_previous_concursos_batch()`
  - Nuevos modelos: `PrediccionConcursoBatchItem` y `PrediccionBatchResponse`
  - Reduce ~10x el n√∫mero de llamadas al LLM
- **Optimizado**: Prompts de predicci√≥n batch
  - Lenguaje afirmativo/declarativo
  - Ejemplos conceptuales sin overfitting
- **Mejorado**: Filtrado de casos no predecibles
  - Detecci√≥n de `self_reference` antes del LLM

### v2.3 - Limpieza Completa de C√≥digo

- **Eliminado**: Funciones obsoletas de gesti√≥n de API keys individuales
- **Sistema unificado**: `APIKeyManager` es la √∫nica forma de gestionar API keys
- **Limpieza**: Eliminados archivos temporales y c√≥digo duplicado

---

**√öltima actualizaci√≥n**: 2025-12-17  
**Versi√≥n de arquitectura**: 4.4
