"""
Predictor de concursos usando LLM

Analiza si dos concursos son el mismo y predice fechas de apertura.
"""

import json
import logging
import time
import requests
import traceback
from datetime import datetime
from typing import Optional, Dict, Any, Tuple, List

from models.prediccion import (
    PrediccionResponse,
    PrediccionConcurso,
    PrediccionBatchResponse,
    PrediccionConcursoBatchItem,
)
from llm.gemini_client import GeminiClient
from config import EXTRACTION_CONFIG, GEMINI_CONFIG

logger = logging.getLogger(__name__)


PREDICTION_SYSTEM_PROMPT = """Eres un analista experto en fondos de financiamiento para investigaci√≥n acad√©mica en Chile.
Tu tarea es analizar concursos y generar predicciones prudentes y bien justificadas sobre futuras fechas de apertura.

Utiliza siempre la fecha actual que se te entrega como referencia temporal.
Entrega fechas que se sit√∫an en el futuro respecto de esa fecha actual y respalda tus decisiones con evidencia clara y expl√≠cita.
No propongas fechas anteriores o iguales a la √∫ltima versi√≥n conocida ni fechas en el pasado respecto de la fecha actual."""

PREDICTION_FROM_PREVIOUS_PROMPT_TEMPLATE = """Analiza el siguiente concurso y su historial de versiones anteriores para estimar CU√ÅNDO se abrir√° la PR√ìXIMA VERSI√ìN FUTURA.

FECHA ACTUAL (referencia temporal): {fecha_actual}

CONCURSO ACTUAL:
- Nombre: {nombre}
- URL: {url}
- Fecha apertura: {fecha_apertura}
- Fecha cierre: {fecha_cierre}
- Organismo: {organismo}
- Descripci√≥n: {descripcion}

CONCURSOS ANTERIORES (versiones hist√≥ricas extra√≠das directamente de la p√°gina):
{previous_concursos_info}

INSTRUCCIONES:
1. Analiza el patr√≥n de fechas de apertura y cierre de las versiones anteriores, observando a√±o, mes y estacionalidad.
2. Identifica la periodicidad dominante (por ejemplo anual, semestral u otra cadencia estable) y el momento t√≠pico del a√±o en que abre el concurso.
3. Propone una fecha de apertura FUTURA coherente con ese patr√≥n y con la fecha actual ({fecha_actual}), estrictamente posterior al √∫ltimo a√±o conocido de apertura.
4. Prioriza fechas que mantengan la misma ventana temporal hist√≥rica (por ejemplo mismos meses o trimestre).
5. Cuando la informaci√≥n es ambigua o sugiere una pr√≥xima versi√≥n demasiado lejana en el tiempo, utiliza una estimaci√≥n prudente y marca fecha_predicha como null.

CONCEPTOS Y EJEMPLOS CONCEPTUALES:
- Ejemplo A (patr√≥n anual claro): versiones 2022, 2023 y 2024 abren en marzo; una pr√≥xima versi√≥n razonable se ubica en marzo del a√±o siguiente.
- Ejemplo B (patr√≥n con cambios leves): versiones 2021 y 2023 abren entre abril y mayo; una pr√≥xima versi√≥n futura razonable se sit√∫a en esa misma ventana de meses del a√±o siguiente disponible.
- Ejemplo C (informaci√≥n insuficiente): una sola versi√≥n previa sin se√±ales claras de recurrencia motiva una estimaci√≥n prudente y favorece fecha_predicha = null con una justificaci√≥n clara.

Mant√©n siempre una justificaci√≥n breve, concreta y f√°cil de entender que explique la relaci√≥n entre el patr√≥n hist√≥rico y la estimaci√≥n propuesta."""

PREDICTION_FROM_PREVIOUS_BATCH_PROMPT_TEMPLATE = """Analiza varios concursos y sus versiones anteriores para estimar CU√ÅNDO se abrir√° la PR√ìXIMA VERSI√ìN FUTURA de cada uno.

FECHA ACTUAL (referencia temporal): {fecha_actual}

CONJUNTO DE CONCURSOS:
{items_block}

TAREA:
1. Examina cada concurso de forma independiente, usando √∫nicamente la informaci√≥n incluida en su bloque.
2. Para cada concurso, analiza la secuencia de versiones anteriores y la relaci√≥n entre a√±os, meses y fechas de apertura y cierre.
3. Identifica la periodicidad dominante y la ventana t√≠pica del a√±o en que se abre el concurso.
4. Propone una fecha de apertura FUTURA prudente, coherente con el patr√≥n hist√≥rico y con la fecha actual, y que sea estrictamente posterior al √∫ltimo a√±o conocido de apertura.
5. Si la informaci√≥n no permite establecer un patr√≥n razonable o la pr√≥xima versi√≥n se ubicar√≠a demasiado lejos, utiliza una estimaci√≥n prudente y establece fecha_predicha como null.

FORMATO DE RESPUESTA:
- Devuelve un √∫nico objeto JSON con la siguiente estructura:
  {{
    \"items\": [
      {{
        \"concurso_url\": \"<URL del concurso>\",
        \"prediccion\": {{
          \"es_mismo_concurso\": true,
          \"fecha_predicha\": \"YYYY-MM-DD\" o null,
          \"justificacion\": \"p√°rrafo breve y claro\"
        }}
      }},
      ...
    ]
  }}

EJEMPLOS CONCEPTUALES (a modo ilustrativo, sin reproducir literalmente):
- Lote 1: varios concursos anuales con aperturas entre marzo y abril se proyectan nuevamente en ese rango de meses del siguiente a√±o disponible.
- Lote 2: concursos con un historial corto o irregular priorizan justificaciones prudentes.
- Lote 3: concursos con historial antiguo y sin nuevas versiones recientes favorecen fecha_predicha = null con una explicaci√≥n clara de la incertidumbre.

Genera una predicci√≥n coherente para cada concurso del lote, manteniendo independencia conceptual entre ellos y utilizando el mismo criterio de an√°lisis hist√≥rico en todos los casos."""


PREDICTION_PROMPT_TEMPLATE = """Analiza si los siguientes dos concursos son esencialmente el mismo (solo difieren en a√±o o versi√≥n) o si son concursos diferentes.

FECHA ACTUAL (referencia temporal, muy importante): {fecha_actual}

CONCURSO 1:
- Nombre: {nombre1}
- URL: {url1}
- Fecha apertura: {fecha_apertura1}
- Fecha cierre: {fecha_cierre1}
- Organismo: {organismo1}
- Descripci√≥n: {descripcion1}
- Contenido completo de la p√°gina:
{page_content1}

CONCURSO 2:
- Nombre: {nombre2}
- URL: {url2}
- Fecha apertura: {fecha_apertura2}
- Fecha cierre: {fecha_cierre2}
- Organismo: {organismo2}
- Descripci√≥n: {descripcion2}
- Contenido completo de la p√°gina:
{page_content2}

INFORMACI√ìN HIST√ìRICA (si est√° disponible):
{historical_info}

INSTRUCCIONES:
1. Determina si son el MISMO concurso (solo difieren en a√±o/versi√≥n) o son DIFERENTES.

2. Si son el mismo concurso:
   - **PRIORIDAD M√ÅXIMA**: Si la informaci√≥n hist√≥rica incluye "CONCURSOS ANTERIORES (informaci√≥n hist√≥rica extra√≠da directamente de la p√°gina)",
     esta informaci√≥n proviene directamente de la secci√≥n "Concursos anteriores" de la p√°gina ANID y es la fuente M√ÅS CONFIABLE.
     * Usa EXCLUSIVAMENTE esta informaci√≥n para analizar patrones y predecir la pr√≥xima apertura.
     * Analiza los intervalos entre versiones anteriores (a√±os, meses, estacionalidad).
     * Calcula el patr√≥n promedio de apertura bas√°ndote en las fechas hist√≥ricas exactas proporcionadas.
     * Esta informaci√≥n es m√°s precisa que cualquier otra fuente hist√≥rica.
   
   - Si NO hay informaci√≥n de "Concursos anteriores", usa la informaci√≥n hist√≥rica disponible del sistema.
   
   - Analiza el patr√≥n hist√≥rico de aperturas/cierres.
   - Predice la fecha de PR√ìXIMA apertura bas√°ndote en:
     * Intervalos hist√≥ricos entre versiones (especialmente si provienen de "Concursos anteriores").
     * Patrones estacionales (meses t√≠picos de apertura).
     * Informaci√≥n del contenido de las p√°ginas.
   
   - LA FECHA PREDICHA DEBE SER SIEMPRE POSTERIOR a la FECHA ACTUAL indicada arriba.
     * No propongas meses/a√±os que ya hayan pasado o sean anteriores/iguales a la fecha actual.
     * Si por el patr√≥n hist√≥rico concluyes que NO HABR√Å NUEVAS CONVOCATORIAS FUTURAS, devuelve fecha_predicha = null.
   
   - Justifica tu decisi√≥n en un p√°rrafo sencillo y claro (m√°ximo 200 palabras). La justificaci√≥n debe ser f√°cil de entender y explicar de forma concisa por qu√© se predice esa fecha bas√°ndose en el patr√≥n hist√≥rico.

3. Si son diferentes:
   - Explica por qu√© son concursos distintos.
   - Justifica tu decisi√≥n.

IMPORTANTE:
- La fecha predicha debe ser en formato YYYY-MM-DD o texto descriptivo claro (ej: "marzo 2026", "primer trimestre 2026") y DEBE corresponder a un momento futuro respecto a la fecha actual.
- La justificaci√≥n debe ser un p√°rrafo sencillo y claro (m√°ximo 200 palabras) que explique la predicci√≥n de forma comprensible. Debe ser concisa y f√°cil de entender.
- Si hay informaci√≥n de "Concursos anteriores", dale M√ÅXIMA PRIORIDAD sobre cualquier otra fuente hist√≥rica.
"""


class ConcursoPredictor:
    """
    Predictor de concursos usando LLM.
    
    Analiza similitud entre concursos y predice fechas de apertura.
    """
    
    def __init__(self, api_key_manager, model_name: Optional[str] = None, config: Optional[Dict[str, Any]] = None):
        """
        Inicializa el predictor.
        
        Args:
            api_key_manager: Gestor de API keys
            model_name: Nombre del modelo a usar (opcional)
            config: Configuraci√≥n adicional (opcional)
        """
        self.api_key_manager = api_key_manager
        self.config = config or {}
        
        # Inicializar cliente de Gemini
        gemini_config = self.config.copy()
        if model_name:
            gemini_config["model"] = model_name
        else:
            gemini_config["model"] = GEMINI_CONFIG.get("model", "gemini-2.5-flash-lite")
        
        self.gemini_client = GeminiClient(
            api_key_manager=api_key_manager,
            config=gemini_config
        )
        
        self.extraction_config = EXTRACTION_CONFIG
    
    def predict_from_previous_concursos(
        self,
        concurso: Dict[str, Any],
        previous_concursos_info: str
    ) -> PrediccionConcurso:
        """
        Predice la fecha de apertura de la pr√≥xima versi√≥n bas√°ndose en informaci√≥n
        de "Concursos anteriores" extra√≠da directamente de la p√°gina.
        
        Args:
            concurso: Diccionario con datos del concurso actual
            previous_concursos_info: Informaci√≥n formateada de concursos anteriores
            
        Returns:
            Objeto PrediccionConcurso con la predicci√≥n
        """
        fecha_actual = datetime.now().strftime("%Y-%m-%d")
        
        prompt = PREDICTION_FROM_PREVIOUS_PROMPT_TEMPLATE.format(
            nombre=concurso.get("nombre", ""),
            url=concurso.get("url", ""),
            fecha_apertura=concurso.get("fecha_apertura", "N/A"),
            fecha_cierre=concurso.get("fecha_cierre", "N/A"),
            organismo=concurso.get("organismo", "N/A"),
            descripcion=concurso.get("descripcion", ""),
            previous_concursos_info=previous_concursos_info,
            fecha_actual=fecha_actual
        )
        
        full_prompt = f"{PREDICTION_SYSTEM_PROMPT}\n\n{prompt}"
        
        logger.info(
            f"üîÆ Prediciendo pr√≥xima versi√≥n para '{concurso.get('nombre')}' "
            f"bas√°ndose en informaci√≥n de 'Concursos anteriores'..."
        )
        
        try:
            response_text = self._call_llm_with_structured_output(full_prompt)
            prediccion = self._parse_prediction_response(response_text)
            # Cuando usamos previous_concursos, siempre es el mismo concurso
            prediccion.es_mismo_concurso = True
            return prediccion
        except Exception as e:
            error_str = str(e)
            error_type = type(e).__name__
            
            # Construir mensaje de error detallado
            detailed_error = f"[{error_type}] {error_str}"
            
            # Agregar contexto adicional seg√∫n el tipo de error
            if isinstance(e, ValueError):
                detailed_error = f"Error de validaci√≥n: {error_str}"
            elif isinstance(e, json.JSONDecodeError):
                detailed_error = f"Error al parsear respuesta JSON: {error_str}"
            elif "Timeout" in error_type or "timeout" in error_str.lower():
                detailed_error = f"Timeout en llamada al LLM: {error_str}"
            elif "Connection" in error_type or "conexi√≥n" in error_str.lower():
                detailed_error = f"Error de conexi√≥n con el LLM: {error_str}"
            elif "429" in error_str or ("quota" in error_str.lower() and "retry in" in error_str.lower()):
                import re
                retry_match = re.search(r'retry in ([\d.]+)s', error_str, re.IGNORECASE)
                if retry_match:
                    retry_after = int(float(retry_match.group(1)))
                    logger.warning(f"‚è±Ô∏è Rate limit temporal al predecir. Esperar {retry_after}s antes de reintentar.")
                    detailed_error = f"Rate limit temporal: {error_str} (esperar {retry_after}s)"
                else:
                    logger.error(f"Error de cuota al predecir desde concursos anteriores: {error_str}")
                    detailed_error = f"Error de cuota: {error_str}"
            else:
                logger.error(f"Error al predecir desde concursos anteriores: [{error_type}] {error_str}")
            
            return PrediccionConcurso(
                es_mismo_concurso=True,
                fecha_predicha=None,
                justificacion=f"Error al analizar: {detailed_error}"
            )

    def predict_from_previous_concursos_batch(
        self,
        concursos_batch: list[dict]
    ) -> Dict[str, PrediccionConcurso]:
        """
        Predice fechas de apertura para un batch de concursos usando informaci√≥n
        de "Concursos anteriores" ya formateada.
        
        Args:
            concursos_batch: Lista de diccionarios con:
                - concurso: datos del concurso actual
                - previous_concursos_info: texto formateado con concursos anteriores
        
        Returns:
            Diccionario {concurso_url: PrediccionConcurso}
        """
        fecha_actual = datetime.now().strftime("%Y-%m-%d")
        
        # Construir bloque de items para el batch
        items_blocks = []
        for idx, item in enumerate(concursos_batch, start=1):
            concurso = item.get("concurso", {})
            previous_info = item.get("previous_concursos_info", "")
            
            block_lines = [
                f"CONCURSO {idx}:",
                f"- URL: {concurso.get('url', '')}",
                f"- Nombre: {concurso.get('nombre', '')}",
                f"- Fecha apertura: {concurso.get('fecha_apertura', 'N/A')}",
                f"- Fecha cierre: {concurso.get('fecha_cierre', 'N/A')}",
                f"- Organismo: {concurso.get('organismo', 'N/A')}",
                f"- Descripci√≥n: {concurso.get('descripcion', '')}",
                "",
                "CONCURSOS ANTERIORES:",
                previous_info,
                "",
            ]
            items_blocks.append("\n".join(block_lines))
        
        items_block = "\n\n".join(items_blocks)
        
        prompt = PREDICTION_FROM_PREVIOUS_BATCH_PROMPT_TEMPLATE.format(
            fecha_actual=fecha_actual,
            items_block=items_block
        )
        full_prompt = f"{PREDICTION_SYSTEM_PROMPT}\n\n{prompt}"
        
        logger.info(
            f"üîÆ Prediciendo pr√≥ximas versiones para un batch de {len(concursos_batch)} concursos "
            f"bas√°ndose en informaci√≥n de 'Concursos anteriores'... "
            f"(maxOutputTokens: 12000 para acomodar {len(concursos_batch)} concursos)"
        )
        
        # Reintentos autom√°ticos para errores de parsing JSON u otros errores recuperables
        max_retries = 3
        last_error = None
        
        for attempt in range(max_retries):
            try:
                response_text = self._call_llm_with_structured_output(
                    full_prompt,
                    response_model=PrediccionBatchResponse,
                    max_output_tokens=12000  # Expl√≠citamente 12000 tokens para batches
                )
                # Si llegamos aqu√≠, el parsing fue exitoso
                return self._parse_prediction_batch_response(response_text)
                
            except (ValueError, json.JSONDecodeError) as e:
                # Error de parsing JSON - reintentar autom√°ticamente
                error_str = str(e)
                error_type = type(e).__name__
                last_error = e
                
                # Log detallado para diagn√≥stico
                if isinstance(e, json.JSONDecodeError):
                    error_details = f"L√≠nea {e.lineno}, columna {e.colno}, posici√≥n {e.pos}"
                else:
                    error_details = error_str
                
                if attempt < max_retries - 1:
                    logger.warning(
                        f"‚ö†Ô∏è Error al parsear respuesta JSON del batch (intento {attempt + 1}/{max_retries}): "
                        f"[{error_type}] {error_details}. "
                        f"Posible causa: respuesta truncada por l√≠mite de tokens. Reintentando autom√°ticamente..."
                    )
                    time.sleep(EXTRACTION_CONFIG.get("retry_delay", 2) * (attempt + 1))
                    continue
                else:
                    # Agotados los reintentos
                    logger.error(
                        f"‚ùå Error al parsear respuesta JSON del batch despu√©s de {max_retries} intentos: "
                        f"[{error_type}] {error_details}. "
                        f"El JSON probablemente se trunc√≥. Considera reducir el tama√±o del batch o aumentar maxOutputTokens."
                    )
                    raise Exception(
                        f"Error cr√≠tico: No se pudo parsear respuesta del LLM despu√©s de {max_retries} reintentos. "
                        f"√öltimo error: [{error_type}] {error_details}. "
                        f"Posible causa: respuesta truncada por l√≠mite de tokens (actualmente 12000). "
                        f"Se detendr√° la ejecuci√≥n de predicciones."
                    ) from e
                    
            except Exception as e:
                error_str = str(e)
                error_type = type(e).__name__
                last_error = e
                
                # Si es un error cr√≠tico que no debe reintentarse (ej: todas las API keys agotadas)
                if "Todas las API keys est√°n agotadas" in error_str or "Error cr√≠tico" in error_str:
                    logger.error(f"‚ùå Error cr√≠tico al predecir batch: [{error_type}] {error_str}")
                    raise
                
                # Para otros errores, reintentar
                if attempt < max_retries - 1:
                    logger.warning(
                        f"‚ö†Ô∏è Error al predecir batch (intento {attempt + 1}/{max_retries}): "
                        f"[{error_type}] {error_str}. Reintentando autom√°ticamente..."
                    )
                    time.sleep(EXTRACTION_CONFIG.get("retry_delay", 2) * (attempt + 1))
                    continue
                else:
                    # Agotados los reintentos
                    logger.error(
                        f"‚ùå Error al predecir batch despu√©s de {max_retries} intentos: "
                        f"[{error_type}] {error_str}"
                    )
                    raise Exception(
                        f"Error cr√≠tico: No se pudo procesar batch despu√©s de {max_retries} reintentos. "
                        f"√öltimo error: [{error_type}] {error_str}. "
                        f"Se detendr√° la ejecuci√≥n de predicciones."
                    ) from e
    
    def predict_concurso_similarity(
        self,
        concurso1: Dict[str, Any],
        concurso2: Dict[str, Any],
        historical_info: Optional[str] = None
    ) -> PrediccionConcurso:
        """
        Analiza si dos concursos son el mismo y predice fecha de apertura.
        
        Args:
            concurso1: Diccionario con datos del primer concurso
            concurso2: Diccionario con datos del segundo concurso
            historical_info: Informaci√≥n hist√≥rica adicional (opcional)
            
        Returns:
            Objeto PrediccionConcurso con la predicci√≥n
        """
        # Construir prompt (incluyendo fecha actual expl√≠cita para evitar fechas en el pasado)
        fecha_actual = datetime.now().strftime("%Y-%m-%d"),
        
        prompt = PREDICTION_PROMPT_TEMPLATE.format(
            nombre1=concurso1.get("nombre", ""),
            url1=concurso1.get("url", ""),
            fecha_apertura1=concurso1.get("fecha_apertura", "N/A"),
            fecha_cierre1=concurso1.get("fecha_cierre", "N/A"),
            organismo1=concurso1.get("organismo", "N/A"),
            descripcion1=concurso1.get("descripcion", "N/A"),
            page_content1=concurso1.get("page_content", "No disponible"),
            nombre2=concurso2.get("nombre", ""),
            url2=concurso2.get("url", ""),
            fecha_apertura2=concurso2.get("fecha_apertura", "N/A"),
            fecha_cierre2=concurso2.get("fecha_cierre", "N/A"),
            organismo2=concurso2.get("organismo", "N/A"),
            descripcion2=concurso2.get("descripcion", "N/A"),
            page_content2=concurso2.get("page_content", "No disponible"),
            historical_info=historical_info or "No hay informaci√≥n hist√≥rica disponible",
            fecha_actual=fecha_actual,
        )
        
        full_prompt = f"{PREDICTION_SYSTEM_PROMPT}\n\n{prompt}"
        
        # Llamar a LLM con structured output (log m√°s expl√≠cito para debug)
        logger.info(
            "ü§ñ Analizando similitud entre concursos:"
            f" '{concurso1.get('nombre')}' ({concurso1.get('url')})"
            f" y '{concurso2.get('nombre')}' ({concurso2.get('url')})..."
        )
        
        try:
            response_text = self._call_llm_with_structured_output(full_prompt)
            prediccion = self._parse_prediction_response(response_text)
            return prediccion
        except Exception as e:
            error_str = str(e)
            # Log simplificado para rate limits temporales
            if "429" in error_str or ("quota" in error_str.lower() and "retry in" in error_str.lower()):
                import re
                retry_match = re.search(r'retry in ([\d.]+)s', error_str, re.IGNORECASE)
                if retry_match:
                    retry_after = int(float(retry_match.group(1)))
                    logger.warning(f"‚è±Ô∏è Rate limit temporal al predecir similitud. Esperar {retry_after}s antes de reintentar.")
                else:
                    logger.error(f"Error al predecir similitud: {error_str}")
            else:
                logger.error(f"Error al predecir similitud: {error_str}")
            # Retornar predicci√≥n por defecto en caso de error
            return PrediccionConcurso(
                es_mismo_concurso=False,
                fecha_predicha=None,
                justificacion=f"Error al analizar: {str(e)}"
            )
    
    def _call_llm_with_structured_output(self, prompt: str, response_model=None, max_output_tokens: Optional[int] = None) -> str:
        """
        Llama al LLM con structured output para garantizar formato correcto.
        
        Args:
            prompt: Prompt completo
            response_model: Modelo Pydantic para la respuesta (opcional)
            max_output_tokens: L√≠mite de tokens de salida (opcional, por defecto 2000 para individual, 12000 para batch)
            
        Returns:
            Texto de respuesta del LLM (JSON v√°lido)
        """
        from models.prediccion import PrediccionResponse, PrediccionBatchResponse
        
        # Modelo de respuesta por defecto (predicci√≥n individual)
        if response_model is None:
            response_model = PrediccionResponse
        
        # Determinar max_output_tokens si no se especifica
        if max_output_tokens is None:
            # Si es batch, usar m√°s tokens; si es individual, usar menos
            if response_model == PrediccionBatchResponse:
                max_output_tokens = 12000  # Suficiente para 10 concursos con justificaciones
            else:
                max_output_tokens = 2000  # Suficiente para predicci√≥n individual
        
        # Obtener esquema JSON del modelo
        json_schema = response_model.model_json_schema()
        
        # URL de la API
        url = f"https://generativelanguage.googleapis.com/v1beta/models/{self.gemini_client.model_name}:generateContent"
        
        headers = {"Content-Type": "application/json"}
        
        payload = {
            "contents": [{
                "parts": [{"text": prompt}]
            }],
            "generationConfig": {
                "temperature": 0.3,  # M√°s bajo para mayor consistencia
                "maxOutputTokens": max_output_tokens,
                "responseMimeType": "application/json",
                "responseJsonSchema": json_schema,
            }
        }
        
        # Timeout
        api_timeout = self.extraction_config.get("api_timeout", 60)
        
        # Intentar con rotaci√≥n de API keys (para errores de cuota, no para timeouts)
        configured_retries = self.extraction_config.get("max_retries", 3)
        total_keys = len(self.api_key_manager.api_keys) if self.api_key_manager else 1
        max_retries = min(configured_retries, total_keys)
        last_error = None
        last_attempt_info = None  # Para debug si llegamos al final sin error
        
        for attempt in range(max_retries):
            last_attempt_info = f"intento {attempt + 1}/{max_retries}"
            try:
                params = {"key": self.gemini_client.api_key}
                response = requests.post(url, json=payload, headers=headers, params=params, timeout=api_timeout)
                
                if response.status_code != 200:
                    error_data = {}
                    try:
                        if response.content:
                            error_data = response.json()
                    except (ValueError, json.JSONDecodeError):
                        error_data = {}
                    error_msg = error_data.get("error", {}).get("message", f"HTTP {response.status_code}")
                    error_code = error_data.get("error", {}).get("code", response.status_code)
                    
                    # Si es error 429 (quota exceeded), rotar inmediatamente
                    if response.status_code == 429 or "429" in error_msg or "quota" in error_msg.lower():
                        logger.warning(f"‚ö†Ô∏è Error de cuota detectado en intento {attempt + 1}/{max_retries}. Rotando API key...")
                        
                        retry_after = None
                        try:
                            import re
                            retry_match = re.search(r'retry in ([\d.]+)s', error_msg, re.IGNORECASE)
                            if retry_match:
                                retry_after = int(float(retry_match.group(1)))
                        except (ValueError, AttributeError):
                            pass
                        
                        # Crear error detallado
                        quota_error = Exception(f"Error de cuota en Gemini API (HTTP {response.status_code}): {error_msg}")
                        last_error = quota_error
                        
                        # Rotar a siguiente key
                        if self.gemini_client._handle_quota_error(quota_error, retry_after):
                            # Log eliminado: se registra en gemini_client.py para evitar redundancia
                            import time
                            time.sleep(EXTRACTION_CONFIG.get("retry_delay", 2))
                            continue  # Reintentar con nueva key
                        else:
                            # No hay m√°s keys disponibles
                            logger.error("‚ùå No hay m√°s API keys disponibles. Todas est√°n agotadas.")
                            # last_error ya est√° establecido arriba (l√≠nea 383)
                            if attempt < max_retries - 1:
                                import time
                                time.sleep(EXTRACTION_CONFIG.get("retry_delay", 2) * (attempt + 1))
                                continue
                            else:
                                raise Exception(f"Todas las API keys est√°n agotadas despu√©s de {max_retries} intentos. √öltimo error: {error_msg}")
                    else:
                        # Otro error HTTP, lanzar excepci√≥n con detalles
                        detailed_error = f"Error de API Gemini (HTTP {response.status_code}): {error_msg}"
                        if error_data:
                            error_details = error_data.get("error", {})
                            if error_details.get("status"):
                                detailed_error += f" [Status: {error_details['status']}]"
                            if error_details.get("code"):
                                detailed_error += f" [Code: {error_details['code']}]"
                        raise Exception(detailed_error)
                
                try:
                    result = response.json()
                except json.JSONDecodeError as json_err:
                    # Error al parsear JSON de respuesta HTTP
                    last_error = Exception(f"Error al parsear respuesta JSON de Gemini API (HTTP {response.status_code}): {str(json_err)}. Respuesta recibida: {response.text[:200]}")
                    self.api_key_manager.record_api_call(self.gemini_client.api_key, success=False)
                    if attempt < max_retries - 1:
                        import time
                        time.sleep(EXTRACTION_CONFIG.get("retry_delay", 2))
                        continue
                    else:
                        raise last_error
                
                # Extraer texto de respuesta
                if "candidates" in result and len(result["candidates"]) > 0:
                    content = result["candidates"][0].get("content", {})
                    parts = content.get("parts", [])
                    if parts and "text" in parts[0]:
                        self.api_key_manager.record_api_call(self.gemini_client.api_key, success=True)
                        return parts[0]["text"].strip()
                    else:
                        # Detectar el tipo espec√≠fico de problema
                        if "candidates" in result and len(result["candidates"]) > 0:
                            candidate = result["candidates"][0]
                            if "finishReason" in candidate:
                                finish_reason = candidate["finishReason"]
                                if finish_reason == "SAFETY":
                                    raise Exception("Respuesta bloqueada por filtros de seguridad de Gemini")
                                elif finish_reason == "RECITATION":
                                    raise Exception("Respuesta bloqueada por detecci√≥n de recitaci√≥n (contenido duplicado)")
                                elif finish_reason == "OTHER":
                                    raise Exception(f"Respuesta bloqueada por Gemini (finishReason: {finish_reason})")
                                else:
                                    raise Exception(f"No se encontr√≥ texto en la respuesta de Gemini (finishReason: {finish_reason})")
                            else:
                                raise Exception("No se encontr√≥ texto en la respuesta de Gemini (candidato sin finishReason)")
                        else:
                            raise Exception("No se encontr√≥ texto en la respuesta de Gemini (sin candidatos)")
                else:
                    # Respuesta sin candidatos - puede ser bloqueo o error
                    if "promptFeedback" in result:
                        feedback = result["promptFeedback"]
                        if feedback.get("blockReason"):
                            block_reason = feedback["blockReason"]
                            raise Exception(f"Prompt bloqueado por Gemini (blockReason: {block_reason})")
                    raise Exception(f"Respuesta inesperada de Gemini: sin candidatos. Respuesta completa: {str(result)[:500]}")
                    
            except requests.Timeout as e:
                logger.error(f"‚è±Ô∏è Timeout despu√©s de {api_timeout}s en llamada de predicci√≥n. No se rotar√° de key para evitar marcar todas como agotadas.")
                # No rotar ni marcar como agotada por timeout: reintentar solo hasta max_retries
                if attempt < max_retries - 1:
                    logger.warning(f"‚ö†Ô∏è Reintentando en {EXTRACTION_CONFIG.get('retry_delay', 2)}s con la MISMA API key...")
                    import time
                    time.sleep(EXTRACTION_CONFIG.get("retry_delay", 2) * (attempt + 1))
                    last_error = Exception(f"Timeout de {api_timeout}s excedido en llamada a Gemini API (intento {attempt + 1}/{max_retries})")
                    continue
                else:
                    raise Exception(f"Timeout de {api_timeout}s excedido despu√©s de {max_retries} intentos en llamada a Gemini API")
            except requests.ConnectionError as e:
                logger.error(f"üîå Error de conexi√≥n: {e}")
                # Para errores de conexi√≥n, no rotar (no es problema de cuota)
                error_detail = str(e)
                if "Name resolution failed" in error_detail or "DNS" in error_detail:
                    raise Exception(f"Error de conexi√≥n con Gemini API: No se pudo resolver el nombre del servidor (DNS)")
                elif "Connection refused" in error_detail:
                    raise Exception(f"Error de conexi√≥n con Gemini API: Conexi√≥n rechazada por el servidor")
                elif "timeout" in error_detail.lower():
                    raise Exception(f"Error de conexi√≥n con Gemini API: Timeout al establecer conexi√≥n")
                else:
                    raise Exception(f"Error de conexi√≥n con Gemini API: {error_detail}")
            except json.JSONDecodeError as e:
                # Error al parsear JSON de respuesta
                last_error = Exception(f"Error al parsear respuesta JSON de Gemini API: {str(e)}. Posible respuesta corrupta o inv√°lida.")
                self.api_key_manager.record_api_call(self.gemini_client.api_key, success=False)
                if attempt < max_retries - 1:
                    import time
                    time.sleep(EXTRACTION_CONFIG.get("retry_delay", 2))
                    continue
                else:
                    raise last_error
            except Exception as e:
                last_error = e
                error_str = str(e)
                error_type = type(e).__name__
                self.api_key_manager.record_api_call(self.gemini_client.api_key, success=False)
                
                # Si es error de cuota y no se manej√≥ arriba, intentar rotar
                if ("429" in error_str or "quota" in error_str.lower() or 
                    "ResourceExhausted" in error_type):
                    logger.warning(f"‚ö†Ô∏è Error de cuota detectado en excepci√≥n. Rotando API key...")
                    
                    retry_after = None
                    try:
                        import re
                        retry_match = re.search(r'retry in ([\d.]+)s', error_str, re.IGNORECASE)
                        if retry_match:
                            retry_after = int(float(retry_match.group(1)))
                    except (ValueError, AttributeError):
                        pass
                    
                    if self.gemini_client._handle_quota_error(e, retry_after):
                        # Log eliminado: se registra en gemini_client.py para evitar redundancia
                        import time
                        time.sleep(EXTRACTION_CONFIG.get("retry_delay", 2))
                        # last_error ya est√° establecido arriba
                        continue  # Reintentar con nueva key
                    else:
                        if attempt < max_retries - 1:
                            import time
                            time.sleep(EXTRACTION_CONFIG.get("retry_delay", 2) * (attempt + 1))
                            # last_error ya est√° establecido arriba
                            continue
                        else:
                            raise Exception(f"Todas las API keys est√°n agotadas despu√©s de {max_retries} intentos. √öltimo error: [{error_type}] {error_str}")
                else:
                    # Otro tipo de error, mejorar mensaje y no reintentar
                    enhanced_error = Exception(f"Error inesperado al llamar a Gemini API (intento {attempt + 1}/{max_retries}): [{error_type}] {error_str}")
                    raise enhanced_error from e
        
        # Si llegamos aqu√≠, todos los intentos fallaron
        if last_error:
            # Mejorar el mensaje de error con m√°s contexto
            error_type = type(last_error).__name__
            error_msg = str(last_error)
            
            # Construir mensaje detallado
            detailed_error = f"Error al llamar al LLM despu√©s de {max_retries} intentos: [{error_type}] {error_msg}"
            
            # Si es un error HTTP, agregar m√°s detalles
            if hasattr(last_error, 'response') and last_error.response is not None:
                status_code = getattr(last_error.response, 'status_code', None)
                if status_code:
                    detailed_error += f" (HTTP {status_code})"
            
            raise Exception(detailed_error) from last_error
        else:
            # Este caso no deber√≠a ocurrir, pero si ocurre, es un bug en la l√≥gica
            # Intentar crear un error gen√©rico con informaci√≥n de contexto
            error_context = f"max_retries={max_retries}, last_attempt={last_attempt_info if last_attempt_info else 'N/A'}"
            logger.error(f"‚ö†Ô∏è BUG: Se lleg√≥ al final del loop de reintentos sin capturar ning√∫n error. {error_context}")
            # Crear un error gen√©rico pero informativo
            generic_error = Exception(
                f"Error desconocido al llamar al LLM despu√©s de {max_retries} intentos. "
                f"No se captur√≥ ning√∫n error espec√≠fico en ning√∫n intento. "
                f"Esto indica un problema en la l√≥gica de manejo de errores. "
                f"Contexto: {error_context}"
            )
            last_error = generic_error
            raise generic_error
    
    def _parse_prediction_response(self, response_text: str) -> PrediccionConcurso:
        """
        Parsea la respuesta del LLM a un objeto PrediccionConcurso.
        
        Args:
            response_text: Texto JSON de respuesta
            
        Returns:
            Objeto PrediccionConcurso
        """
        # Limpiar si viene envuelto en markdown
        if "```json" in response_text:
            import re
            match = re.search(r'```json\s*(\{.*?\})\s*```', response_text, re.DOTALL)
            if match:
                response_text = match.group(1)
        elif "```" in response_text:
            import re
            match = re.search(r'```\s*(\{.*?\})\s*```', response_text, re.DOTALL)
            if match:
                response_text = match.group(1)
        
        # Parsear JSON
        try:
            data = json.loads(response_text)
            
            # Validar estructura
            if "prediccion" not in data:
                # Intentar detectar qu√© campos tiene la respuesta
                available_keys = list(data.keys()) if isinstance(data, dict) else "no es un objeto"
                raise ValueError(f"Respuesta del LLM no contiene campo 'prediccion'. Campos disponibles: {available_keys}")
            
            prediccion_data = data["prediccion"]
            
            # Validar que prediccion_data es un diccionario
            if not isinstance(prediccion_data, dict):
                raise ValueError(f"Campo 'prediccion' no es un objeto v√°lido. Tipo recibido: {type(prediccion_data).__name__}")
            
            # Crear objeto PrediccionConcurso con validaci√≥n detallada
            try:
                return PrediccionConcurso(**prediccion_data)
            except TypeError as e:
                # Detectar qu√© campos faltan o son inv√°lidos
                required_fields = ["es_mismo_concurso", "fecha_predicha", "justificacion"]
                missing_fields = [f for f in required_fields if f not in prediccion_data]
                if missing_fields:
                    raise ValueError(f"Faltan campos requeridos en la respuesta del LLM: {missing_fields}. Campos presentes: {list(prediccion_data.keys())}")
                else:
                    raise ValueError(f"Error al crear PrediccionConcurso: {str(e)}. Datos recibidos: {prediccion_data}")
            
        except json.JSONDecodeError as e:
            logger.error(f"Error al parsear JSON de predicci√≥n: {e}")
            logger.error(f"Respuesta recibida (primeros 500 chars): {response_text[:500]}")
            raise ValueError(f"Respuesta del LLM no es JSON v√°lido: {str(e)}. Posici√≥n del error: l√≠nea {e.lineno}, columna {e.colno}")
        except ValueError as e:
            # Re-lanzar ValueError con m√°s contexto
            logger.error(f"Error de validaci√≥n al procesar respuesta del LLM: {e}")
            raise
        except Exception as e:
            error_type = type(e).__name__
            logger.error(f"Error inesperado al procesar respuesta del LLM: [{error_type}] {str(e)}")
            raise Exception(f"Error al procesar respuesta del LLM: [{error_type}] {str(e)}") from e

    def _parse_prediction_batch_response(self, response_text: str) -> Dict[str, PrediccionConcurso]:
        """
        Parsea la respuesta del LLM para un batch de concursos.
        
        Args:
            response_text: Texto JSON de respuesta
            
        Returns:
            Diccionario {concurso_url: PrediccionConcurso}
        """
        # Limpiar si viene envuelto en markdown
        if "```json" in response_text:
            import re
            match = re.search(r'```json\s*(\{.*?\})\s*```', response_text, re.DOTALL)
            if match:
                response_text = match.group(1)
        elif "```" in response_text:
            import re
            match = re.search(r'```\s*(\{.*?\})\s*```', response_text, re.DOTALL)
            if match:
                response_text = match.group(1)
        
        try:
            data = json.loads(response_text)
            
            if "items" not in data or not isinstance(data["items"], list):
                available_keys = list(data.keys()) if isinstance(data, dict) else "no es un objeto"
                raise ValueError(
                    f"Respuesta del LLM para batch no contiene lista 'items' v√°lida. "
                    f"Campos disponibles: {available_keys}"
                )
            
            result: Dict[str, PrediccionConcurso] = {}
            for raw_item in data["items"]:
                try:
                    item = PrediccionConcursoBatchItem(**raw_item)
                    result[item.concurso_url] = item.prediccion
                except Exception as e:
                    logger.error(
                        f"Error al validar elemento de batch en respuesta del LLM: {e}. "
                        f"Datos recibidos: {raw_item}"
                    )
                    continue
            
            return result
        except json.JSONDecodeError as e:
            logger.error(f"Error al parsear JSON de predicci√≥n (batch): {e}")
            logger.error(f"Respuesta recibida (primeros 500 chars): {response_text[:500]}")
            raise ValueError(
                f"Respuesta del LLM (batch) no es JSON v√°lido: {str(e)}. "
                f"Posici√≥n del error: l√≠nea {e.lineno}, columna {e.colno}"
            )
        except ValueError as e:
            logger.error(f"Error de validaci√≥n al procesar respuesta de batch del LLM: {e}")
            raise
        except Exception as e:
            error_type = type(e).__name__
            logger.error(f"Error inesperado al procesar respuesta de batch del LLM: [{error_type}] {str(e)}")
            raise Exception(
                f"Error al procesar respuesta de batch del LLM: [{error_type}] {str(e)}"
            ) from e

    # M√©todo deprecated: la asignaci√≥n de confianza fue eliminada.
    def assign_confidence_batch(self, concursos_data: list, max_retries: int = 3) -> dict:
        return {}
